[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About The Team\nMembers: Wang Yizao, Li Zhongchao"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FindingNEMO",
    "section": "",
    "text": "Welcome to Group 17’s Homepage."
  },
  {
    "objectID": "Project Proposal.html",
    "href": "Project Proposal.html",
    "title": "Team 17 Project Proposal",
    "section": "",
    "text": "In general, we have Several commercial software packages in market to draw data and their summaries. However,ideally, such tools should be open source, freely available and allow contributions or modifications by users. Inspired by Prof Kam, with the acquired coding skills and understanding of data ,this group project aims to create such flexible website by making use of interactive visualizations to answer questions from Visual Analytics Project to find out the Impact Of Climate Change In Singapore."
  },
  {
    "objectID": "Project Proposal.html#question-1",
    "href": "Project Proposal.html#question-1",
    "title": "Team 17 Project Proposal",
    "section": "Question 1",
    "text": "Question 1\n\nPOWER\nPower generation is one of the major sources of Singapore’s carbon emissions and accounts for about 40% of our emissions today. With our limited capacity to tap on alternative energy sources, we currently rely heavily on imported natural gas to power our nation.\nThey will be evaluated based on:\n\nNatural Gas;\n\nSince 2000, Singapore has shifted away from less efficient fossil fuels and in turn increased the percentage of natural gas used in electricity generation from 19% to more than 95% today."
  },
  {
    "objectID": "Project Proposal.html#question-2",
    "href": "Project Proposal.html#question-2",
    "title": "Team 17 Project Proposal",
    "section": "Question 2",
    "text": "Question 2\n\nHOUSEHOLDS\nSingapore has taken steps to reduce energy consumption of the household sector, which accounts for about 15% of our total electricity consumption. The Minimum Energy Performance Standards which have been progressively tightened over the years, improves the energy efficiency of household appliances such as refrigerators, air-conditioners, clothes dryers and lamps.\nThey will be evaluated based on:\n\nenergy-saving habits\n\nHouseholds can also reduce their energy consumption use by practising simple energy-saving habits."
  },
  {
    "objectID": "Project Proposal.html#question-3",
    "href": "Project Proposal.html#question-3",
    "title": "Team 17 Project Proposal",
    "section": "Question 3",
    "text": "Question 3\n\nCARBON TAX\nSingapore’s carbon tax underpins our net zero targets and climate mitigation efforts by providing an effective economic signal to steer producers and consumers away from carbon-intensive goods and services, hold businesses accountable for their emissions, and enhance the business case for the development of low-carbon solutions. In all, the carbon tax currently covers 80% of our total greenhouse gas (GHG) emissions from about 50 facilities in the manufacturing, power, waste, and water sectors. The carbon tax forms part of Singapore’s comprehensive suite of mitigation measures to support the transition to a low-carbon economy.\nThey will be evaluated based on:\n\nCarbon Tax in Singapore from 2019 to 2023\n\nSingapore implemented a carbon tax, the first carbon pricing scheme in Southeast Asia, on 1 January 2019. The carbon tax level was set at S$5/tCO2e for the first five years from 2019 to 2023 to provide a transitional period for emitters to adjust."
  },
  {
    "objectID": "proposal/proposal.html",
    "href": "proposal/proposal.html",
    "title": "VAST Mini-Challenge 3: Proposal",
    "section": "",
    "text": "Weather \n\n Project Overview\nWeather\n\n\n Project Objectives\nThis study aims to address the following tasks in sequence:\n\n\n Proposed Methodology\n\n\n\n\nflowchart LR\n  A{Task 1:\\nIdentify\\nAnomalies} --&gt;|patterns?|B[products or\\nservices]\n  A --&gt;|suspicious?|C[revenue]\n  A --&gt;|abnormal?|D[links]\n  A -.- E{Task 2:\\nGrouping} -.- I{Tasks 3&4}\n  E --&gt;|overlaps?|F(Company Contacts)\n  E --&gt;|overlaps?|G(Beneficial Owners)\n  E --&gt;|similarities?|H(Country)\n  E --&gt;|similarities?|C\n  E --&gt;|similarities?|B\n  I --&gt; J([Evaluative Metrics])\n\n\n\n\n\n\n\n Shiny App\nThe proposed Shiny App will be an interactive Network Graph visualising different groups of"
  },
  {
    "objectID": "prototyping/clustering.html",
    "href": "prototyping/clustering.html",
    "title": "clustering",
    "section": "",
    "text": "In this article, we will reviewing and exploring the timetk and tidyvert family R packages, where will be conducting an overall comparison analysis to look at how the different collection work for time series forecasting using the targeted dataset. The article would be spitted into two article where the the first article would be about the different in data manipulation and feature selection method for timetk against tidyvert. Whereas in the second article would be on the reviewing of the forecasting methodology between timetk and tidyvert\nFor part 1 of the series of the article, in the first section of the article, we would looking into the current techniques used by tidyvert collection on how the data structure is being set up to perform data cleaning and wrangling after the extraction of dataset via web scrapping. After which, we will be reviewing the ability to perform feature engineering to look at how time series features, decompositions, statistical summaries and convenient visualizations could be perform by tidyvert collection.\nIn the next section of the article, we would be looking at the same concept but with the use of the timetk collection instead. Lastly, we will be reviewing both collection to analysis its similarities vs difference as well the strengthen and cases to use individual collection."
  },
  {
    "objectID": "prototyping/clustering.html#feasts",
    "href": "prototyping/clustering.html#feasts",
    "title": "clustering",
    "section": "feasts",
    "text": "feasts\nfeasts package that is within the tidyvert collection is mainly used for the feature extraction and statistics for time series analysis. Also, feasts package provides a set of tools within the package that it is useful for the analysis of time series data.\nWorking with tidy temporal data that was previously set up using tsibble package, it is able to compute time series features, decomposition, statistical summaries and graphical visualizations. Features extraction is useful in the understanding of the behavior of time series data together with the closely integration of the tidy forecasting workflow used in the fable package.\n\nTime series pattern (time plot)\nTo begin our analysis, we will first start with plotting a time plot using the auto_plot() function to look at the time plot of our dataset. auto_plot() automatically create an appropriate plot of choosen variable against time. In this case, it recognizes humidity level as a time series and produces a time plot as shown below.\nFrom the figure below, we are able to observe that the humidity level fluctuate of high volatility that cause the understanding of the time plot to be rather challenging. In the next few section of the the article we will be looking into the different analysis of the time plot to try to identify if we are able to observed any trend/seasonal/cyclic pattern.\n\n# Filter for specific stations\nweather_filtered &lt;- weather %&gt;% \n  filter(Station %in% c(\"Admiralty\", \"Ang Mo Kio\", \"Changi\"))\n\n# Create a date column from Year and Month\nweather_filtered$Date &lt;- make_date(weather_filtered$Year, weather_filtered$Month)\n\n# Summarize the total rainfall by month for each station\nmonthly_rainfall &lt;- weather_filtered %&gt;%\n  group_by(Station, Day) %&gt;%\n  summarise(Total_Rainfall = sum(Daily.Rainfall.Total..mm., na.rm = TRUE))\n\n`summarise()` has grouped output by 'Station'. You can override using the\n`.groups` argument.\n\n# Plot the data\nggplot(monthly_rainfall, aes(x = Day, y = Total_Rainfall, color = Station)) +\n  geom_line() +\n  labs(title = \"Monthly Rainfall by Station\", x = \"Date\", y = \"Total Rainfall (mm)\") +\n  theme_minimal()\n\n\n\n\n\n\nSeasonal plot and seasonal subseries plot\nWith the feasts package, user is able to plot time plot based on the given time period in the dataset. We are also able to use the gg_season() and gg_subseries() to plot the season plot and there change in the seasonality respectively. Without the use of group_by() function, we are able to review the time plot of individual airport using gg_season() and gg_subseries() function. The code below would shown how we are able to use gg_season() to plot the different season plot based on individual airport. Similar technique is used for gg_subseries as well.\nweather_tsibble &lt;- weather_filtered %&gt;%\nmutate(Year = year(Date), Month = month(Date)) %&gt;%\ngroup_by(Station, Year, Month) %&gt;%\nsummarise(Total_Rainfall = sum(Daily.Rainfall.Total..mm., na.rm = TRUE)) %&gt;%\nungroup() %&gt;%\nmutate(Date = make_date(Year, Month)) %&gt;%\nselect(-Year, -Month) %&gt;%\nas_tsibble(index = Date, key = Station)\n# Seasonal decomposition using the feasts package\nweather_decomposed &lt;- weather_tsibble %&gt;%\nmodel(STL(Total_Rainfall ~ season(window = “periodic”)))\n\nweather_tsibble &lt;- weather_filtered %&gt;%\n  mutate(Year = year(Date), Month = month(Date)) %&gt;%\n  group_by(Station, Year, Month) %&gt;%\n  summarise(Total_Rainfall = sum(Daily.Rainfall.Total..mm., na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  mutate(Date = make_date(Year, Month)) %&gt;%\n  select(-Year, -Month) %&gt;%\n  as_tsibble(index = Date, key = Station)\n\n`summarise()` has grouped output by 'Station', 'Year'. You can override using\nthe `.groups` argument.\n\n# Seasonal decomposition using the feasts package\nweather_decomposed &lt;- weather_tsibble %&gt;%\n  model(STL(Total_Rainfall ~ season(window = \"periodic\")))\n\nWarning: 2 errors (1 unique) encountered for STL(Total_Rainfall ~ season(window = \"periodic\"))\n[2] .data contains implicit gaps in time. You should check your data and convert implicit gaps into explicit missing values using `tsibble::fill_gaps()` if required.\n\n\n\nweather_tsibble &lt;- weather_tsibble %&gt;%\n  mutate(Week = factor(isoweek(Date))) %&gt;%\n  as_tsibble(index = Date, key = Station) %&gt;%\n  fill_gaps() %&gt;% # This will fill in the implicit gaps with NA by default\n  mutate(Total_Rainfall = replace_na(Total_Rainfall, 0)) # Replace NA with 0 or use another method to handle NAs\n\n# Now, create the seasonal plots\nseasonal_plots &lt;- weather_tsibble %&gt;%\n  gg_season(Total_Rainfall, period = \"week\") +\n  labs(title = \"Seasonal Plot by Week\",\n       subtitle = \"Individual time plot for each Station\",\n       y = \"Measurement Variable\") +\n  facet_wrap(~ Station, scales = \"free_y\", ncol = 1) +\n  aes(color = Week) +\n  scale_color_manual(values = rainbow(length(unique(weather_tsibble$Week))))\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n# Print the seasonal plots\nprint(seasonal_plots)\n\n\n\n\n\nseasonal_plots &lt;- weather_tsibble %&gt;%\n  gg_season(Total_Rainfall, period = \"week\") +\n  labs(title = \"Seasonal Plot by Week\",\n       subtitle = \"Individual time plot for each Station\",\n       y = \"Measurement Variable\") +\n  facet_wrap(~ Station, scales = \"free_y\", ncol = 1) +\n  aes(color = Week) +\n  scale_color_manual(values = rainbow(length(unique(weather_tsibble$Week))))\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\nprint(seasonal_plots)\n\n\n\n\n\n\nLag plots\nLag plot would be an one of the approach to look a correlation of lagged observation (vertical axis) against the current observation, with points colored hourly in a scatterplot format.The correlations of the lag plots shown with the code below using the gg_lag() are what that make up the ACF. Where the stronger the correlation the closer the scatterplot point will be to the dotted line"
  },
  {
    "objectID": "prototyping/data_prep.html",
    "href": "prototyping/data_prep.html",
    "title": "Prototyping",
    "section": "",
    "text": "pacman::p_load(tidyverse, naniar, imputeTS, DT, knitr, lubridate,\n               ggplot2, patchwork, ggthemes,\n               tseries, ggHoriPlot,dplyr,\n               TSclust, fable, dtwclust, dendextend,\n               ggraph, plotly, factoextra, ggdendrosf,terra,gstat,tmap,viridis,tidyverse,dplyr)\n\nInstalling package into 'C:/Users/Yizao/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: package 'ggdendrosf' is not available for this version of R\n\nA version of this package for your version of R might be available elsewhere,\nsee the ideas at\nhttps://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\nWarning: 'BiocManager' not available.  Could not check Bioconductor.\n\nPlease use `install.packages('BiocManager')` and then retry.\n\n\nWarning in p_install(package, character.only = TRUE, ...):\n\n\nWarning in library(package, lib.loc = lib.loc, character.only = TRUE,\nlogical.return = TRUE, : there is no package called 'ggdendrosf'\n\n\nInstalling package into 'C:/Users/Yizao/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'tmap' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Yizao\\AppData\\Local\\Temp\\Rtmp2RxNLc\\downloaded_packages\n\n\n\ntmap installed\n\n\nWarning: package 'tmap' was built under R version 4.3.3\n\n\nWarning in pacman::p_load(tidyverse, naniar, imputeTS, DT, knitr, lubridate, : Failed to install/load:\nggdendrosf, tmap\nimport data:\nimport the merged data of all the stations across 10 years (2014-2023)\nrfdata &lt;- read.csv('data/merged_data.csv')\nImport the data that includes the latitude and longitude of the weather stations in Singapore.\nrfstation &lt;- read.csv('data/RainfallStation.csv')\n\nrfstation &lt;- rfstation %&gt;%\n  rename(Station = Station.Code)\nJoin the latitude and longitude to the rfdata, so that in the analysis part we can map the geospatial analysis.\nraw_weather_data &lt;- rfdata  %&gt;%\n  left_join(rfstation, by = \"Station\")\nhis dataset was retrieved from the Meteorological Service Singapore site, and had some basic pre-processing steps performed in python due to the large amount of files:"
  },
  {
    "objectID": "prototyping/data_prep.html#check-structure-with-glimpse",
    "href": "prototyping/data_prep.html#check-structure-with-glimpse",
    "title": "Prototyping",
    "section": "Check structure with glimpse()",
    "text": "Check structure with glimpse()\n\nglimpse(raw_weather_data)\n\nRows: 204,464\nColumns: 15\n$ Station                       &lt;chr&gt; \"Paya Lebar\", \"Paya Lebar\", \"Paya Lebar\"…\n$ Year                          &lt;int&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014…\n$ Month                         &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Day                           &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1…\n$ Daily.Rainfall.Total..mm.     &lt;chr&gt; \"0\", \"0\", \"2.2\", \"0.6\", \"10.5\", \"31.2\", …\n$ Highest.30.min.Rainfall..mm.  &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", …\n$ Highest.60.min.Rainfall..mm.  &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", …\n$ Highest.120.min.Rainfall..mm. &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", …\n$ Mean.Temperature...C.         &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", …\n$ Maximum.Temperature...C.      &lt;chr&gt; \"29.5\", \"31.7\", \"31.1\", \"32.3\", \"27\", \"2…\n$ Minimum.Temperature...C.      &lt;chr&gt; \"24.8\", \"25\", \"25.1\", \"23.7\", \"23.8\", \"2…\n$ Mean.Wind.Speed..km.h.        &lt;chr&gt; \"15.8\", \"16.5\", \"14.9\", \"8.9\", \"11.9\", \"…\n$ Max.Wind.Speed..km.h.         &lt;chr&gt; \"35.3\", \"37.1\", \"33.5\", \"35.3\", \"33.5\", …\n$ Latitude                      &lt;dbl&gt; 1.3524, 1.3524, 1.3524, 1.3524, 1.3524, …\n$ Longitude                     &lt;dbl&gt; 103.9007, 103.9007, 103.9007, 103.9007, …\n\n\nThere are 204464 rows, and 15 columns in the dataset. In the next few steps, we will drop specific columns and rows based on the project focus."
  },
  {
    "objectID": "prototyping/data_prep.html#filter-dataset-for-desired-period",
    "href": "prototyping/data_prep.html#filter-dataset-for-desired-period",
    "title": "Prototyping",
    "section": "Filter dataset for desired period",
    "text": "Filter dataset for desired period\nWhile the dataset contains 10 years of data from 2014 to 2023, we will focus on the most recent dataset for a 3 year period, from 2021 to 2024. This period was chosen to maximise the overall availability of data across the stations.\n\nraw_weather_data &lt;- raw_weather_data %&gt;%\n  filter(Year &gt;= 2021)\nprint(paste(\"The dataset covers the period from\", min(raw_weather_data$Year, na.rm = TRUE), \"to\", max(raw_weather_data$Year, na.rm = TRUE), \".\"))\n\n[1] \"The dataset covers the period from 2021 to 2024 .\""
  },
  {
    "objectID": "prototyping/data_prep.html#drop-unused-columns",
    "href": "prototyping/data_prep.html#drop-unused-columns",
    "title": "Prototyping",
    "section": "Drop unused columns",
    "text": "Drop unused columns\nWe will not be using all 15 columns for this project. The following columns will be dropped:\n\nHighest 30 Min Rainfall (mm)\nHighest 60 Min Rainfall (mm)\nHighest 1200 Min Rainfall (mm)\nMean Wind Speed (km/h)\nMax Wind Speed (km/h)\n\n\n# Drop columns\nraw_weather_data &lt;- raw_weather_data %&gt;%\n  select(-c(`Highest.30.min.Rainfall..mm.`, \n            `Highest.60.min.Rainfall..mm.`, \n            `Highest.120.min.Rainfall..mm.`,\n            `Mean.Wind.Speed..km.h.`,\n            `Max.Wind.Speed..km.h.`))"
  },
  {
    "objectID": "prototyping/data_prep.html#remove-rows-for-specific-stations",
    "href": "prototyping/data_prep.html#remove-rows-for-specific-stations",
    "title": "Prototyping",
    "section": "Remove rows for specific Stations",
    "text": "Remove rows for specific Stations\nThe Meteorological Service Singapore also provides a file, Station Records that has some information on the availability of data for each station. After examining the station records file, we found that 41 stations had missing information for some variables. We will hence drop rows for these stations.\n\n# Drop rows of 41 stations\n# Define the station names to remove\nstations_to_remove &lt;- c(\"Macritchie Reservoir\", \"Lower Peirce Reservoir\", \"Pasir Ris (West)\", \"Kampong Bahru\", \"Jurong Pier\", \"Ulu Pandan\", \"Serangoon\", \"Jurong (East)\", \"Mandai\", \"Upper Thomson\", \"Buangkok\", \"Boon Lay (West)\", \"Bukit Panjang\", \"Kranji Reservoir\", \"Tanjong Pagar\", \"Admiralty West\", \"Queenstown\", \"Tanjong Katong\", \"Chai Chee\", \"Upper Peirce Reservoir\", \"Kent Ridge\", \"Somerset (Road)\", \"Punggol\", \"Tuas West\", \"Simei\", \"Toa Payoh\", \"Tuas\", \"Bukit Timah\", \"Yishun\", \"Buona Vista\", \"Pasir Ris (Central)\", \"Jurong (North)\", \"Choa Chu Kang (West)\", \"Serangoon North\", \"Lim Chu Kang\", \"Marine Parade\", \"Choa Chu Kang (Central)\", \"Dhoby Ghaut\", \"Nicoll Highway\", \"Botanic Garden\", \"Whampoa\")\n\n# Remove rows with the specified station names\nraw_weather_data &lt;- raw_weather_data[!raw_weather_data$Station %in% stations_to_remove, ]\n\n# Print the number of stations left\nprint(sprintf(\"There were %d stations removed.There are %d stations left.\", length(stations_to_remove), n_distinct(raw_weather_data$Station)))\n\n[1] \"There were 41 stations removed.There are 21 stations left.\""
  },
  {
    "objectID": "prototyping/data_prep.html#check-for-duplicates",
    "href": "prototyping/data_prep.html#check-for-duplicates",
    "title": "Prototyping",
    "section": "Check for duplicates",
    "text": "Check for duplicates\n\n# Identify duplicates\nduplicates &lt;- raw_weather_data[duplicated(raw_weather_data[c(\"Station\", \"Year\", \"Month\", \"Day\")]) | duplicated(raw_weather_data[c(\"Station\", \"Year\", \"Month\", \"Day\")], fromLast = TRUE), ]\n\n# Check if 'duplicates' dataframe is empty\nif (nrow(duplicates) == 0) {\n  print(\"The combination of Station Name, Year, Month, and Day is unique.\")\n} else {\n  print(\"There are duplicates in the combination of Station Name, Year, Month, and Day. Showing duplicated rows:\")\n  print(duplicates)\n}\n\n[1] \"The combination of Station Name, Year, Month, and Day is unique.\""
  },
  {
    "objectID": "prototyping/data_prep.html#check-and-handle-missing-values",
    "href": "prototyping/data_prep.html#check-and-handle-missing-values",
    "title": "Prototyping",
    "section": "Check and handle missing values",
    "text": "Check and handle missing values\n\nFirst check for missing values\nMissing values in this dataset can be represented by:\n\n\\u0097\nNA\n-\n\nWe first replace these values with actual NA values:\n\nraw_weather_data &lt;- raw_weather_data %&gt;%\n  mutate(across(where(is.character), ~na_if(.x, \"\\u0097\"))) %&gt;%\n  mutate(across(where(is.character), ~na_if(.x, \"NA\"))) %&gt;%\n  mutate(across(where(is.character), ~na_if(.x, \"-\")))\n\nNext, we visualize the missing values in the dataset:\n\nvis_miss(raw_weather_data)\n\n\n\n\nWe will take steps to handle the missing data.\n\n\nRemove Stations with significant missing data\nWe have identified two checks to make:\n\nCheck which stations have no recorded data for entire months.\nCheck which stations have more than 7 consecutive days of missing data\n\nFor both these checks, we will remove the entire station from the dataset as it would not be practical to impute such large amounts of missing values.\n\nIdentify and remove Stations with no recorded data for entire months\nSome stations have no recorded data for entire months, as summarised in the table below:\n\n# Create complete combination of Station, Year, and Month\nall_combinations &lt;- expand.grid(\n  Station = unique(raw_weather_data$Station),\n  Year = 2021:2023,\n  Month = 1:12\n)\n\n# Left join this with the original weather data to identify missing entries\nmissing_months &lt;- all_combinations %&gt;%\n  left_join(raw_weather_data, by = c(\"Station\", \"Year\", \"Month\")) %&gt;%\n  # Use is.na() to check for rows that didn't have a match in the original data\n  filter(is.na(Day)) %&gt;%\n  # Select only the relevant columns for the final output\n  select(Station, Year, Month)\n\n# Create a summary table that lists out the missing months\nmissing_months_summary &lt;- missing_months %&gt;%\n  group_by(Station, Year) %&gt;%\n  summarise(MissingMonths = toString(sort(unique(Month))), .groups = 'drop')\n\nkable(missing_months_summary)\n\n\n\n\nStation\nYear\nMissingMonths\n\n\n\n\nKhatib\n2022\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\nKhatib\n2023\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\n\n\n\nWe hence drop these stations from our dataset:\n\nraw_weather_data &lt;- anti_join(raw_weather_data, missing_months, by = \"Station\")\n\nprint(sprintf(\"The folowing %d stations were dropped: %s\", n_distinct(missing_months$Station), paste(unique(missing_months$Station), collapse = \", \")))\n\n[1] \"The folowing 1 stations were dropped: Khatib\"\n\n\n\nprint(sprintf(\"There are %d stations left: \", n_distinct(raw_weather_data$Station)))\n\n[1] \"There are 20 stations left: \"\n\n\n\nkable(unique(raw_weather_data$Station),\n      row.names = TRUE,\n      col.names = \"Station\",\n      caption = \"List of Remaining Stations\")\n\n\nList of Remaining Stations\n\n\n\nStation\n\n\n\n\n1\nPaya Lebar\n\n\n2\nSemakau Island\n\n\n3\nAdmiralty\n\n\n4\nPulau Ubin\n\n\n5\nEast Coast Parkway\n\n\n6\nMarina Barrage\n\n\n7\nAng Mo Kio\n\n\n8\nJurong Island\n\n\n9\nNewton\n\n\n10\nTuas South\n\n\n11\nPasir Panjang\n\n\n12\nChoa Chu Kang (South)\n\n\n13\nTengah\n\n\n14\nSeletar\n\n\n15\nChangi\n\n\n16\nTai Seng\n\n\n17\nJurong (West)\n\n\n18\nClementi\n\n\n19\nSentosa Island\n\n\n20\nSembawang"
  },
  {
    "objectID": "prototyping/data_prep.html#summary-of-cleaned-data",
    "href": "prototyping/data_prep.html#summary-of-cleaned-data",
    "title": "Prototyping",
    "section": "Summary of cleaned data",
    "text": "Summary of cleaned data\n\nDetails of stations and time period of data\n\nprint(sprintf(\"There are %d stations: \", n_distinct(raw_weather_data$Station)))\n\n[1] \"There are 20 stations: \"\n\n\n\nkable(unique(raw_weather_data$Station),\n      row.names = TRUE,\n      col.names = \"Station\",\n      caption = \"List of Stations\")\n\n\nList of Stations\n\n\n\nStation\n\n\n\n\n1\nPaya Lebar\n\n\n2\nSemakau Island\n\n\n3\nAdmiralty\n\n\n4\nPulau Ubin\n\n\n5\nEast Coast Parkway\n\n\n6\nMarina Barrage\n\n\n7\nAng Mo Kio\n\n\n8\nJurong Island\n\n\n9\nNewton\n\n\n10\nTuas South\n\n\n11\nPasir Panjang\n\n\n12\nChoa Chu Kang (South)\n\n\n13\nTengah\n\n\n14\nSeletar\n\n\n15\nChangi\n\n\n16\nTai Seng\n\n\n17\nJurong (West)\n\n\n18\nClementi\n\n\n19\nSentosa Island\n\n\n20\nSembawang\n\n\n\n\n\n\n\nCheck structure with glimpse()\n\nglimpse(raw_weather_data)\n\nRows: 22,520\nColumns: 10\n$ Station                   &lt;chr&gt; \"Paya Lebar\", \"Paya Lebar\", \"Paya Lebar\", \"P…\n$ Year                      &lt;int&gt; 2022, 2022, 2022, 2022, 2022, 2022, 2022, 20…\n$ Month                     &lt;int&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, …\n$ Day                       &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1…\n$ Daily.Rainfall.Total..mm. &lt;chr&gt; \"6.8\", \"7.2\", \"14.2\", \"3\", \"36.4\", \"4.8\", \"1…\n$ Mean.Temperature...C.     &lt;chr&gt; \"27.7\", \"27.3\", \"26.4\", \"26.5\", \"26.6\", \"26.…\n$ Maximum.Temperature...C.  &lt;chr&gt; \"33.8\", \"33.5\", \"32.8\", \"30.4\", \"30\", \"32.9\"…\n$ Minimum.Temperature...C.  &lt;chr&gt; \"24.4\", \"24\", \"23.3\", \"24.2\", \"23.7\", \"24.8\"…\n$ Latitude                  &lt;dbl&gt; 1.3524, 1.3524, 1.3524, 1.3524, 1.3524, 1.35…\n$ Longitude                 &lt;dbl&gt; 103.9007, 103.9007, 103.9007, 103.9007, 103.…\n\n\n\n\nView dataset as interactive table\n\nmonsumdata &lt;- raw_weather_data %&gt;%\n  mutate(`Daily.Rainfall.Total..mm.` = as.numeric(gsub(\",\", \"\", `Daily.Rainfall.Total..mm.`)))\n\n\nmonsumdata &lt;- monsumdata %&gt;%\n  group_by(Station, Latitude, Longitude) %&gt;%  # grouping by Station, Year, and Month if you want monthly sums\n  summarise(MONTHSUM = sum(Daily.Rainfall.Total..mm., na.rm = TRUE)) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'Station', 'Latitude'. You can override\nusing the `.groups` argument."
  },
  {
    "objectID": "prototyping/data_prep.html#save-cleaned-data-to-.rds",
    "href": "prototyping/data_prep.html#save-cleaned-data-to-.rds",
    "title": "Prototyping",
    "section": "Save cleaned data to .rds",
    "text": "Save cleaned data to .rds\n\nwrite_rds(monsumdata, \"data/monsumdata.rds\")"
  },
  {
    "objectID": "prototyping/data_prep.html#import-cleaned-data",
    "href": "prototyping/data_prep.html#import-cleaned-data",
    "title": "Prototyping",
    "section": "Import cleaned data",
    "text": "Import cleaned data\nThe below code can be used to import the cleaned data.\n\nweather_data &lt;- read_rds(\"data/monsumdata.rds\") \n# weather_data &lt;- read_rds(\"data/monsumdata.rds\")"
  },
  {
    "objectID": "prototyping/eda.html",
    "href": "prototyping/eda.html",
    "title": "EDA",
    "section": "",
    "text": "For this Take Home Exercise, there are several task needs to be done to create the Shiny application.\n\nTo evaluate and determine the necessary R packages needed for your Shiny application are supported in R CRAN,\nTo prepare and test the specific R codes can be run and returned the correct output as expected,\nTo determine the parameters and outputs that will be exposed on the Shiny applications, and\nTo select the appropriate Shiny UI components for exposing the parameters determine above.\n\nThis submission includes the prototype report for the group project, which will includes:\n\nthe data preparation process,\nthe selection of data visualization techniques used,\nand the data visualization design and interactivity principles and best practices implemented.\n\nBased on the discussion with team member i will be focusing on the Exploratory Data Analysis & Confirmatory Data Analysis, and the UI design for our Shiny app."
  },
  {
    "objectID": "prototyping/eda.html#check-structure-with-glimpse",
    "href": "prototyping/eda.html#check-structure-with-glimpse",
    "title": "EDA",
    "section": "4.1 Check structure with glimpse()",
    "text": "4.1 Check structure with glimpse()\n\nglimpse(raw_weather_data)\n\nRows: 204,464\nColumns: 15\n$ Station                       &lt;chr&gt; \"Paya Lebar\", \"Paya Lebar\", \"Paya Lebar\"…\n$ Year                          &lt;int&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014…\n$ Month                         &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Day                           &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1…\n$ Daily.Rainfall.Total..mm.     &lt;chr&gt; \"0\", \"0\", \"2.2\", \"0.6\", \"10.5\", \"31.2\", …\n$ Highest.30.min.Rainfall..mm.  &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", …\n$ Highest.60.min.Rainfall..mm.  &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", …\n$ Highest.120.min.Rainfall..mm. &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", …\n$ Mean.Temperature...C.         &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", …\n$ Maximum.Temperature...C.      &lt;chr&gt; \"29.5\", \"31.7\", \"31.1\", \"32.3\", \"27\", \"2…\n$ Minimum.Temperature...C.      &lt;chr&gt; \"24.8\", \"25\", \"25.1\", \"23.7\", \"23.8\", \"2…\n$ Mean.Wind.Speed..km.h.        &lt;chr&gt; \"15.8\", \"16.5\", \"14.9\", \"8.9\", \"11.9\", \"…\n$ Max.Wind.Speed..km.h.         &lt;chr&gt; \"35.3\", \"37.1\", \"33.5\", \"35.3\", \"33.5\", …\n$ Latitude                      &lt;dbl&gt; 1.3524, 1.3524, 1.3524, 1.3524, 1.3524, …\n$ Longitude                     &lt;dbl&gt; 103.9007, 103.9007, 103.9007, 103.9007, …\n\n\nThere are 204464 rows, and 15 columns in the dataset. We see that there are missing values shown as ‘?’ in the dataset. In the next few steps, we will drop specific columns and rows based on the project focus."
  },
  {
    "objectID": "prototyping/eda.html#drop-unused-columns",
    "href": "prototyping/eda.html#drop-unused-columns",
    "title": "EDA",
    "section": "4.2 Drop unused columns",
    "text": "4.2 Drop unused columns\nWe will not be using all 15 columns for this project. The following columns will be dropped:\n\nHighest 30 Min Rainfall (mm)\nHighest 60 Min Rainfall (mm)\nHighest 1200 Min Rainfall (mm)\nMean Wind Speed (km/h)\nMax Wind Speed (km/h)\n\n\nraw_weather_data &lt;- raw_weather_data %&gt;%\n  select(-c(`Highest.30.min.Rainfall..mm.`, \n            `Highest.60.min.Rainfall..mm.`, \n            `Highest.120.min.Rainfall..mm.`,\n            `Mean.Wind.Speed..km.h.`,\n            `Max.Wind.Speed..km.h.`))"
  },
  {
    "objectID": "prototyping/eda.html#remove-rows-for-specific-stations",
    "href": "prototyping/eda.html#remove-rows-for-specific-stations",
    "title": "EDA",
    "section": "4.3 Remove rows for specific Stations",
    "text": "4.3 Remove rows for specific Stations\nThe Meteorological Service Singapore also provides a file, Station Records that has some information on the availability of data for each station. After examining the station records file, we found that 41 stations had missing information for some variables. We will hence drop rows for these stations.\n\n# Drop rows of 41 stations\n# Define the station names to remove\nstations_to_remove &lt;- c(\"Macritchie Reservoir\", \"Lower Peirce Reservoir\", \"Pasir Ris (West)\", \"Kampong Bahru\", \"Jurong Pier\", \"Ulu Pandan\", \"Serangoon\", \"Jurong (East)\", \"Mandai\", \"Upper Thomson\", \"Buangkok\", \"Boon Lay (West)\", \"Bukit Panjang\", \"Kranji Reservoir\", \"Tanjong Pagar\", \"Admiralty West\", \"Queenstown\", \"Tanjong Katong\", \"Chai Chee\", \"Upper Peirce Reservoir\", \"Kent Ridge\", \"Somerset (Road)\", \"Punggol\", \"Tuas West\", \"Simei\", \"Toa Payoh\", \"Tuas\", \"Bukit Timah\", \"Yishun\", \"Buona Vista\", \"Pasir Ris (Central)\", \"Jurong (North)\", \"Choa Chu Kang (West)\", \"Serangoon North\", \"Lim Chu Kang\", \"Marine Parade\", \"Choa Chu Kang (Central)\", \"Dhoby Ghaut\", \"Nicoll Highway\", \"Botanic Garden\", \"Whampoa\")\n\n# Remove rows with the specified station names\nraw_weather_data &lt;- raw_weather_data[!raw_weather_data$Station %in% stations_to_remove, ]\n\n# Print the number of stations left\nprint(sprintf(\" %d stations removed. %d stations left.\", length(stations_to_remove), n_distinct(raw_weather_data$Station)))\n\n[1] \" 41 stations removed. 22 stations left.\""
  },
  {
    "objectID": "prototyping/eda.html#check-for-duplicates",
    "href": "prototyping/eda.html#check-for-duplicates",
    "title": "EDA",
    "section": "4.4 Check for duplicates",
    "text": "4.4 Check for duplicates\n\n# Identify duplicates\nduplicates &lt;- raw_weather_data[duplicated(raw_weather_data[c(\"Station\", \"Year\", \"Month\", \"Day\")]) | duplicated(raw_weather_data[c(\"Station\", \"Year\", \"Month\", \"Day\")], fromLast = TRUE), ]\n\n# Check if 'duplicates' dataframe is empty\nif (nrow(duplicates) == 0) {\n  print(\"The combination of Station Name, Year, Month, and Day is unique.\")\n} else {\n  print(\"There are duplicates in the combination of Station Name, Year, Month, and Day. Showing duplicated rows:\")\n  print(duplicates)\n}\n\n[1] \"There are duplicates in the combination of Station Name, Year, Month, and Day. Showing duplicated rows:\"\n               Station Year Month Day Daily.Rainfall.Total..mm.\n13381   Semakau Island   NA    NA  NA                         -\n13382   Semakau Island   NA    NA  NA                         -\n13383   Semakau Island   NA    NA  NA                         -\n13384   Semakau Island   NA    NA  NA                         -\n13385   Semakau Island   NA    NA  NA                         -\n13386   Semakau Island   NA    NA  NA                         -\n13387   Semakau Island   NA    NA  NA                         -\n13388   Semakau Island   NA    NA  NA                         -\n13389   Semakau Island   NA    NA  NA                         -\n13390   Semakau Island   NA    NA  NA                         -\n13391   Semakau Island   NA    NA  NA                         -\n13392   Semakau Island   NA    NA  NA                         -\n13393   Semakau Island   NA    NA  NA                         -\n13394   Semakau Island   NA    NA  NA                         -\n13395   Semakau Island   NA    NA  NA                         -\n13396   Semakau Island   NA    NA  NA                         -\n13397   Semakau Island   NA    NA  NA                         -\n13398   Semakau Island   NA    NA  NA                         -\n13399   Semakau Island   NA    NA  NA                         -\n13400   Semakau Island   NA    NA  NA                         -\n13401   Semakau Island   NA    NA  NA                         -\n13402   Semakau Island   NA    NA  NA                         -\n13403   Semakau Island   NA    NA  NA                         -\n13404   Semakau Island   NA    NA  NA                         -\n13405   Semakau Island   NA    NA  NA                         -\n13406   Semakau Island   NA    NA  NA                         -\n13407   Semakau Island   NA    NA  NA                         -\n13408   Semakau Island   NA    NA  NA                         -\n13409   Semakau Island   NA    NA  NA                         -\n13410   Semakau Island   NA    NA  NA                         -\n13411   Semakau Island   NA    NA  NA                         -\n13412   Semakau Island   NA    NA  NA                         -\n13413   Semakau Island   NA    NA  NA                         -\n13414   Semakau Island   NA    NA  NA                         -\n13415   Semakau Island   NA    NA  NA                         -\n13416   Semakau Island   NA    NA  NA                         -\n13417   Semakau Island   NA    NA  NA                         -\n13418   Semakau Island   NA    NA  NA                         -\n13419   Semakau Island   NA    NA  NA                         -\n13420   Semakau Island   NA    NA  NA                         -\n13421   Semakau Island   NA    NA  NA                         -\n13422   Semakau Island   NA    NA  NA                         -\n13423   Semakau Island   NA    NA  NA                         -\n13424   Semakau Island   NA    NA  NA                         -\n13425   Semakau Island   NA    NA  NA                         -\n13426   Semakau Island   NA    NA  NA                         -\n13427   Semakau Island   NA    NA  NA                         -\n13428   Semakau Island   NA    NA  NA                         -\n13429   Semakau Island   NA    NA  NA                         -\n13430   Semakau Island   NA    NA  NA                         -\n13431   Semakau Island   NA    NA  NA                         -\n13432   Semakau Island   NA    NA  NA                         -\n13433   Semakau Island   NA    NA  NA                         -\n13434   Semakau Island   NA    NA  NA                         -\n13435   Semakau Island   NA    NA  NA                         -\n13436   Semakau Island   NA    NA  NA                         -\n13437   Semakau Island   NA    NA  NA                         -\n13438   Semakau Island   NA    NA  NA                         -\n13439   Semakau Island   NA    NA  NA                         -\n13440   Semakau Island   NA    NA  NA                         -\n13441   Semakau Island   NA    NA  NA                         -\n14084   Semakau Island   NA    NA  NA                         -\n14085   Semakau Island   NA    NA  NA                         -\n14086   Semakau Island   NA    NA  NA                         -\n14087   Semakau Island   NA    NA  NA                         -\n14088   Semakau Island   NA    NA  NA                         -\n183829 Boon Lay (East)   NA    NA  NA                         -\n183830 Boon Lay (East)   NA    NA  NA                         -\n183831 Boon Lay (East)   NA    NA  NA                         -\n183832 Boon Lay (East)   NA    NA  NA                         -\n183833 Boon Lay (East)   NA    NA  NA                         -\n183834 Boon Lay (East)   NA    NA  NA                         -\n183835 Boon Lay (East)   NA    NA  NA                         -\n183836 Boon Lay (East)   NA    NA  NA                         -\n183837 Boon Lay (East)   NA    NA  NA                         -\n183838 Boon Lay (East)   NA    NA  NA                         -\n183839 Boon Lay (East)   NA    NA  NA                         -\n183840 Boon Lay (East)   NA    NA  NA                         -\n183841 Boon Lay (East)   NA    NA  NA                         -\n183842 Boon Lay (East)   NA    NA  NA                         -\n183843 Boon Lay (East)   NA    NA  NA                         -\n183844 Boon Lay (East)   NA    NA  NA                         -\n183845 Boon Lay (East)   NA    NA  NA                         -\n183846 Boon Lay (East)   NA    NA  NA                         -\n183847 Boon Lay (East)   NA    NA  NA                         -\n183848 Boon Lay (East)   NA    NA  NA                         -\n183849 Boon Lay (East)   NA    NA  NA                         -\n183850 Boon Lay (East)   NA    NA  NA                         -\n183851 Boon Lay (East)   NA    NA  NA                         -\n183852 Boon Lay (East)   NA    NA  NA                         -\n183853 Boon Lay (East)   NA    NA  NA                         -\n183854 Boon Lay (East)   NA    NA  NA                         -\n183855 Boon Lay (East)   NA    NA  NA                         -\n183856 Boon Lay (East)   NA    NA  NA                         -\n183857 Boon Lay (East)   NA    NA  NA                         -\n183858 Boon Lay (East)   NA    NA  NA                         -\n191071 Boon Lay (East)   NA    NA  NA                         -\n191072 Boon Lay (East)   NA    NA  NA                         -\n191073 Boon Lay (East)   NA    NA  NA                         -\n191074 Boon Lay (East)   NA    NA  NA                         -\n191075 Boon Lay (East)   NA    NA  NA                         -\n191076 Boon Lay (East)   NA    NA  NA                         -\n191077 Boon Lay (East)   NA    NA  NA                         -\n191078 Boon Lay (East)   NA    NA  NA                         -\n191079 Boon Lay (East)   NA    NA  NA                         -\n191080 Boon Lay (East)   NA    NA  NA                         -\n191081 Boon Lay (East)   NA    NA  NA                         -\n191082 Boon Lay (East)   NA    NA  NA                         -\n191083 Boon Lay (East)   NA    NA  NA                         -\n191084 Boon Lay (East)   NA    NA  NA                         -\n191085 Boon Lay (East)   NA    NA  NA                         -\n191086 Boon Lay (East)   NA    NA  NA                         -\n191087 Boon Lay (East)   NA    NA  NA                         -\n191088 Boon Lay (East)   NA    NA  NA                         -\n191089 Boon Lay (East)   NA    NA  NA                         -\n191090 Boon Lay (East)   NA    NA  NA                         -\n191091 Boon Lay (East)   NA    NA  NA                         -\n191092 Boon Lay (East)   NA    NA  NA                         -\n191093 Boon Lay (East)   NA    NA  NA                         -\n191094 Boon Lay (East)   NA    NA  NA                         -\n191095 Boon Lay (East)   NA    NA  NA                         -\n191096 Boon Lay (East)   NA    NA  NA                         -\n191097 Boon Lay (East)   NA    NA  NA                         -\n191098 Boon Lay (East)   NA    NA  NA                         -\n191099 Boon Lay (East)   NA    NA  NA                         -\n191100 Boon Lay (East)   NA    NA  NA                         -\n191101 Boon Lay (East)   NA    NA  NA                         -\n       Mean.Temperature...C. Maximum.Temperature...C. Minimum.Temperature...C.\n13381                      -                        -                        -\n13382                      -                        -                        -\n13383                      -                        -                        -\n13384                      -                        -                        -\n13385                      -                        -                        -\n13386                      -                        -                        -\n13387                      -                        -                        -\n13388                      -                        -                        -\n13389                      -                        -                        -\n13390                      -                        -                        -\n13391                      -                        -                        -\n13392                      -                        -                        -\n13393                      -                        -                        -\n13394                      -                        -                        -\n13395                      -                        -                        -\n13396                      -                        -                        -\n13397                      -                        -                        -\n13398                      -                        -                        -\n13399                      -                        -                        -\n13400                      -                        -                        -\n13401                      -                        -                        -\n13402                      -                        -                        -\n13403                      -                        -                        -\n13404                      -                        -                        -\n13405                      -                        -                        -\n13406                      -                        -                        -\n13407                      -                        -                        -\n13408                      -                        -                        -\n13409                      -                        -                        -\n13410                      -                        -                        -\n13411                      -                        -                        -\n13412                      -                        -                        -\n13413                      -                        -                        -\n13414                      -                        -                        -\n13415                      -                        -                        -\n13416                      -                        -                        -\n13417                      -                        -                        -\n13418                      -                        -                        -\n13419                      -                        -                        -\n13420                      -                        -                        -\n13421                      -                        -                        -\n13422                      -                        -                        -\n13423                      -                        -                        -\n13424                      -                        -                        -\n13425                      -                        -                        -\n13426                      -                        -                        -\n13427                      -                        -                        -\n13428                      -                        -                        -\n13429                      -                        -                        -\n13430                      -                        -                        -\n13431                      -                        -                        -\n13432                      -                        -                        -\n13433                      -                        -                        -\n13434                      -                        -                        -\n13435                      -                        -                        -\n13436                      -                        -                        -\n13437                      -                        -                        -\n13438                      -                        -                        -\n13439                      -                        -                        -\n13440                      -                        -                        -\n13441                      -                        -                        -\n14084                      -                        -                        -\n14085                      -                        -                        -\n14086                      -                        -                        -\n14087                      -                        -                        -\n14088                      -                        -                        -\n183829                     -                        -                        -\n183830                     -                        -                        -\n183831                     -                        -                        -\n183832                     -                        -                        -\n183833                     -                        -                        -\n183834                     -                        -                        -\n183835                     -                        -                        -\n183836                     -                        -                        -\n183837                     -                        -                        -\n183838                     -                        -                        -\n183839                     -                        -                        -\n183840                     -                        -                        -\n183841                     -                        -                        -\n183842                     -                        -                        -\n183843                     -                        -                        -\n183844                     -                        -                        -\n183845                     -                        -                        -\n183846                     -                        -                        -\n183847                     -                        -                        -\n183848                     -                        -                        -\n183849                     -                        -                        -\n183850                     -                        -                        -\n183851                     -                        -                        -\n183852                     -                        -                        -\n183853                     -                        -                        -\n183854                     -                        -                        -\n183855                     -                        -                        -\n183856                     -                        -                        -\n183857                     -                        -                        -\n183858                     -                        -                        -\n191071                     -                        -                        -\n191072                     -                        -                        -\n191073                     -                        -                        -\n191074                     -                        -                        -\n191075                     -                        -                        -\n191076                     -                        -                        -\n191077                     -                        -                        -\n191078                     -                        -                        -\n191079                     -                        -                        -\n191080                     -                        -                        -\n191081                     -                        -                        -\n191082                     -                        -                        -\n191083                     -                        -                        -\n191084                     -                        -                        -\n191085                     -                        -                        -\n191086                     -                        -                        -\n191087                     -                        -                        -\n191088                     -                        -                        -\n191089                     -                        -                        -\n191090                     -                        -                        -\n191091                     -                        -                        -\n191092                     -                        -                        -\n191093                     -                        -                        -\n191094                     -                        -                        -\n191095                     -                        -                        -\n191096                     -                        -                        -\n191097                     -                        -                        -\n191098                     -                        -                        -\n191099                     -                        -                        -\n191100                     -                        -                        -\n191101                     -                        -                        -\n       Latitude Longitude\n13381    1.1890  103.7680\n13382    1.1890  103.7680\n13383    1.1890  103.7680\n13384    1.1890  103.7680\n13385    1.1890  103.7680\n13386    1.1890  103.7680\n13387    1.1890  103.7680\n13388    1.1890  103.7680\n13389    1.1890  103.7680\n13390    1.1890  103.7680\n13391    1.1890  103.7680\n13392    1.1890  103.7680\n13393    1.1890  103.7680\n13394    1.1890  103.7680\n13395    1.1890  103.7680\n13396    1.1890  103.7680\n13397    1.1890  103.7680\n13398    1.1890  103.7680\n13399    1.1890  103.7680\n13400    1.1890  103.7680\n13401    1.1890  103.7680\n13402    1.1890  103.7680\n13403    1.1890  103.7680\n13404    1.1890  103.7680\n13405    1.1890  103.7680\n13406    1.1890  103.7680\n13407    1.1890  103.7680\n13408    1.1890  103.7680\n13409    1.1890  103.7680\n13410    1.1890  103.7680\n13411    1.1890  103.7680\n13412    1.1890  103.7680\n13413    1.1890  103.7680\n13414    1.1890  103.7680\n13415    1.1890  103.7680\n13416    1.1890  103.7680\n13417    1.1890  103.7680\n13418    1.1890  103.7680\n13419    1.1890  103.7680\n13420    1.1890  103.7680\n13421    1.1890  103.7680\n13422    1.1890  103.7680\n13423    1.1890  103.7680\n13424    1.1890  103.7680\n13425    1.1890  103.7680\n13426    1.1890  103.7680\n13427    1.1890  103.7680\n13428    1.1890  103.7680\n13429    1.1890  103.7680\n13430    1.1890  103.7680\n13431    1.1890  103.7680\n13432    1.1890  103.7680\n13433    1.1890  103.7680\n13434    1.1890  103.7680\n13435    1.1890  103.7680\n13436    1.1890  103.7680\n13437    1.1890  103.7680\n13438    1.1890  103.7680\n13439    1.1890  103.7680\n13440    1.1890  103.7680\n13441    1.1890  103.7680\n14084    1.1890  103.7680\n14085    1.1890  103.7680\n14086    1.1890  103.7680\n14087    1.1890  103.7680\n14088    1.1890  103.7680\n183829   1.3302  103.7205\n183830   1.3302  103.7205\n183831   1.3302  103.7205\n183832   1.3302  103.7205\n183833   1.3302  103.7205\n183834   1.3302  103.7205\n183835   1.3302  103.7205\n183836   1.3302  103.7205\n183837   1.3302  103.7205\n183838   1.3302  103.7205\n183839   1.3302  103.7205\n183840   1.3302  103.7205\n183841   1.3302  103.7205\n183842   1.3302  103.7205\n183843   1.3302  103.7205\n183844   1.3302  103.7205\n183845   1.3302  103.7205\n183846   1.3302  103.7205\n183847   1.3302  103.7205\n183848   1.3302  103.7205\n183849   1.3302  103.7205\n183850   1.3302  103.7205\n183851   1.3302  103.7205\n183852   1.3302  103.7205\n183853   1.3302  103.7205\n183854   1.3302  103.7205\n183855   1.3302  103.7205\n183856   1.3302  103.7205\n183857   1.3302  103.7205\n183858   1.3302  103.7205\n191071   1.3302  103.7205\n191072   1.3302  103.7205\n191073   1.3302  103.7205\n191074   1.3302  103.7205\n191075   1.3302  103.7205\n191076   1.3302  103.7205\n191077   1.3302  103.7205\n191078   1.3302  103.7205\n191079   1.3302  103.7205\n191080   1.3302  103.7205\n191081   1.3302  103.7205\n191082   1.3302  103.7205\n191083   1.3302  103.7205\n191084   1.3302  103.7205\n191085   1.3302  103.7205\n191086   1.3302  103.7205\n191087   1.3302  103.7205\n191088   1.3302  103.7205\n191089   1.3302  103.7205\n191090   1.3302  103.7205\n191091   1.3302  103.7205\n191092   1.3302  103.7205\n191093   1.3302  103.7205\n191094   1.3302  103.7205\n191095   1.3302  103.7205\n191096   1.3302  103.7205\n191097   1.3302  103.7205\n191098   1.3302  103.7205\n191099   1.3302  103.7205\n191100   1.3302  103.7205\n191101   1.3302  103.7205"
  },
  {
    "objectID": "prototyping/eda.html#check-and-handle-missing-values",
    "href": "prototyping/eda.html#check-and-handle-missing-values",
    "title": "EDA",
    "section": "4.5 Check and handle missing values",
    "text": "4.5 Check and handle missing values\n\n4.5.1 First check for missing values\nMissing values in this dataset can be represented by:\n\n\\u0097\nNA\n-\n\nWe first replace these values with actual NA values:\n\nraw_weather_data &lt;- raw_weather_data %&gt;%\n  mutate(across(where(is.character), ~na_if(.x, \"\\u0097\"))) %&gt;%\n  mutate(across(where(is.character), ~na_if(.x, \"NA\"))) %&gt;%\n  mutate(across(where(is.character), ~na_if(.x, \"-\")))\n\nNext, we visualize the missing values in the dataset:\n\n# For a simple missing data plot\ngg_miss_var(raw_weather_data)\n\n\n\n\nWe can see there is quite a number of missing data in the Mean Temperature, Minimum Temperature, Maximum Temperature and Daily Rainfall Total. We will take steps to handle the missing data.\n\n\n4.5.2 Remove Stations with significant missing data\nWe have identified two checks to make:\n\nCheck which stations have no recorded data for entire months.\nCheck which stations have more than 7 consecutive days of missing data\n\nFor both these checks, we will remove the entire station from the dataset as it would not be practical to impute such large amounts of missing values.\n\n4.5.3 Identify and remove Stations with no recorded data for entire months\nSome stations have no recorded data for entire months, as summarised in the table below:\n\n# Create complete combination of Station, Year, and Month\nall_combinations &lt;- expand.grid(\n  Station = unique(raw_weather_data$Station),\n  Year = 2021:2023,\n  Month = 1:12\n)\n\n# Left join this with the original weather data to identify missing entries\nmissing_months &lt;- all_combinations %&gt;%\n  left_join(raw_weather_data, by = c(\"Station\", \"Year\", \"Month\")) %&gt;%\n  # Use is.na() to check for rows that didn't have a match in the original data\n  filter(is.na(Day)) %&gt;%\n  # Select only the relevant columns for the final output\n  select(Station, Year, Month)\n\n# Create a summary table that lists out the missing months\nmissing_months_summary &lt;- missing_months %&gt;%\n  group_by(Station, Year) %&gt;%\n  summarise(MissingMonths = toString(sort(unique(Month))), .groups = 'drop')\n\nkable(missing_months_summary)\n\n\n\n\nStation\nYear\nMissingMonths\n\n\n\n\nBoon Lay (East)\n2021\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\nBoon Lay (East)\n2022\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\nBoon Lay (East)\n2023\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\nKhatib\n2022\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\nKhatib\n2023\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\n\n\n\nWe hence drop these stations from our dataset:\n\nraw_weather_data &lt;- anti_join(raw_weather_data, missing_months, by = \"Station\")\n\nprint(sprintf(\"The folowing %d stations were dropped: %s\", n_distinct(missing_months$Station), paste(unique(missing_months$Station), collapse = \", \")))\n\n[1] \"The folowing 2 stations were dropped: Boon Lay (East), Khatib\"\n\n\n\nprint(sprintf(\"There are %d stations left: \", n_distinct(raw_weather_data$Station)))\n\n[1] \"There are 20 stations left: \"\n\n\n\nkable(unique(raw_weather_data$Station),\n      row.names = TRUE,\n      col.names = \"Station\",\n      caption = \"List of Remaining Stations\")\n\n\nList of Remaining Stations\n\n\n\nStation\n\n\n\n\n1\nPaya Lebar\n\n\n2\nSemakau Island\n\n\n3\nAdmiralty\n\n\n4\nPulau Ubin\n\n\n5\nEast Coast Parkway\n\n\n6\nMarina Barrage\n\n\n7\nAng Mo Kio\n\n\n8\nNewton\n\n\n9\nJurong Island\n\n\n10\nTuas South\n\n\n11\nPasir Panjang\n\n\n12\nChoa Chu Kang (South)\n\n\n13\nTengah\n\n\n14\nChangi\n\n\n15\nSeletar\n\n\n16\nTai Seng\n\n\n17\nJurong (West)\n\n\n18\nClementi\n\n\n19\nSentosa Island\n\n\n20\nSembawang\n\n\n\n\n\n\n\n4.5.4 Identify and remove Stations with excessive missing values\nIf there are any missing values, we can try to impute these missing values. However, if there are 7 or more consecutive values missing, we will remove these stations first.\n\n# Define a helper function to count the number of 7 or more consecutive NAs\ncount_seven_consecutive_NAs &lt;- function(x) {\n  na_runs &lt;- rle(is.na(x))\n  total_consecutive_NAs &lt;- sum(na_runs$lengths[na_runs$values & na_runs$lengths &gt;= 7])\n  return(total_consecutive_NAs)\n}\n\n# Apply the helper function to each relevant column within grouped data\nweather_summary &lt;- raw_weather_data %&gt;%\n  group_by(Station, Year, Month) %&gt;%\n  summarise(across(-Day, ~ count_seven_consecutive_NAs(.x), .names = \"count_consec_NAs_{.col}\"), .groups = \"drop\")\n\n# Filter to keep only rows where there is at least one column with 7 or more consecutive missing values\nweather_summary_with_consecutive_NAs &lt;- weather_summary %&gt;%\n  filter(if_any(starts_with(\"count_consec_NAs_\"), ~ . &gt; 0))\n\n# View the result\nprint(sprintf(\"There are %d stations with 7 or more consecutive missing values.\", n_distinct(weather_summary_with_consecutive_NAs$Station)))\n\n[1] \"There are 13 stations with 7 or more consecutive missing values.\"\n\n\n\n# kable(weather_summary_with_consecutive_NAs)\ndatatable(weather_summary_with_consecutive_NAs, \n            class= \"compact\",\n            rownames = FALSE,\n            width=\"100%\", \n            options = list(pageLength = 10, scrollX=T),\n          caption = 'Details of stations with &gt;=7 missing values')\n\n\n\n\n\n\nWe hence drop these stations from our dataset:\n\nraw_weather_data &lt;- anti_join(raw_weather_data, weather_summary_with_consecutive_NAs, by = \"Station\")\n\nprint(sprintf(\"The folowing %d stations were dropped: %s\", n_distinct(weather_summary_with_consecutive_NAs$Station), paste(unique(weather_summary_with_consecutive_NAs$Station), collapse = \", \")))\n\n[1] \"The folowing 13 stations were dropped: Admiralty, Ang Mo Kio, Clementi, Jurong Island, Marina Barrage, Paya Lebar, Pulau Ubin, Seletar, Semakau Island, Sembawang, Sentosa Island, Tengah, Tuas South\"\n\n\n\nprint(sprintf(\"There are %d stations left: \", n_distinct(raw_weather_data$Station)))\n\n[1] \"There are 7 stations left: \"\n\n\n\nkable(unique(raw_weather_data$Station),\n      row.names = TRUE,\n      col.names = \"Station\",\n      caption = \"List of Remaining Stations\")\n\n\nList of Remaining Stations\n\n\n\nStation\n\n\n\n\n1\nEast Coast Parkway\n\n\n2\nNewton\n\n\n3\nPasir Panjang\n\n\n4\nChoa Chu Kang (South)\n\n\n5\nChangi\n\n\n6\nTai Seng\n\n\n7\nJurong (West)\n\n\n\n\n\n\n\n\n4.5.5 Second check for missing values\nFrom the check below we see there are still missing values in our data. We will impute these values in the next step.\n\n# For a simple missing data plot\ngg_miss_var(raw_weather_data)\n\n\n\n\nWe can see that there is still a few missing values from the selected stations.\n\n\n4.6 Impute missing values\nTo handle the missing values for the remaining Stations, we will impute missing values using simple moving average from imputeTS package.\n\nraw_weather_data &lt;- raw_weather_data %&gt;%\n  mutate(Date = as.Date(paste(Year, Month, Day, sep = \"-\"))) %&gt;%\n  relocate(Date, .after = 1)\n\n\n# Define the weather variables to loop through\nweather_variables &lt;- c(\"Daily.Rainfall.Total..mm.\", \"Mean.Temperature...C.\", \"Maximum.Temperature...C.\", \"Minimum.Temperature...C.\")\n\n# Ensure raw_weather_data is correctly copied to a new data frame for imputation\nweather_data_imputed &lt;- raw_weather_data\n\n# Loop through each weather variable to impute missing values\nfor(variable in weather_variables) {\n  # Convert variable to numeric, ensuring that the conversion warnings are handled if necessary\n  weather_data_imputed[[variable]] &lt;- as.numeric(as.character(weather_data_imputed[[variable]]))\n  \n  # Impute missing values using a moving average\n  weather_data_imputed &lt;- weather_data_imputed %&gt;%\n    group_by(Station) %&gt;%\n    arrange(Station, Date) %&gt;%\n    mutate(\"{variable}\" := round(na_ma(.data[[variable]], k = 7, weighting = \"simple\"), 1)) %&gt;%\n    ungroup()\n}\n\n\n\n4.7 Add specific columns to data [NEW]\nThese columns are added as they may be used in plots later.\n\nweather_data_imputed &lt;- weather_data_imputed %&gt;% \n  mutate(Date_mine = make_date(2023, month(Date), day(Date)),\n         Month_Name = factor(months(Date), levels = month.name),\n         Week = isoweek(Date),\n         Weekday = wday(Date)\n  )"
  },
  {
    "objectID": "prototyping/eda.html#summary-of-cleaned-data",
    "href": "prototyping/eda.html#summary-of-cleaned-data",
    "title": "EDA",
    "section": "4.8 Summary of cleaned data",
    "text": "4.8 Summary of cleaned data\n\nDetails of stations and time period of data\n\ntime_period_start &lt;- min(weather_data_imputed$Date)\ntime_period_end &lt;- max(weather_data_imputed$Date)\ncat(\"\\nThe time period of the dataset is from\", format(time_period_start, \"%Y-%m-%d\"),\"to\", format(time_period_end, \"%Y-%m-%d\"), \"\\n\")\n\n\nThe time period of the dataset is from 2014-01-01 to 2024-01-31 \n\n\nbut i only want to keep until 2023, exclude record in 2024\n\nweather_data_imputed &lt;- subset(weather_data_imputed, Date &lt;= as.Date(\"2023-12-31\"))\n\ntime_period_start &lt;- min(weather_data_imputed$Date)\ntime_period_end &lt;- max(weather_data_imputed$Date)\ncat(\"\\nThe time period of the dataset is from\", format(time_period_start, \"%Y-%m-%d\"),\"to\", format(time_period_end, \"%Y-%m-%d\"), \"\\n\")\n\n\nThe time period of the dataset is from 2014-01-01 to 2023-12-31 \n\n\nAnd also to ease further analysis, convert year, month, day to factor data type:\n\nweather_data_imputed &lt;- weather_data_imputed %&gt;%\n  mutate_at(vars(Year,Month,Day),as.factor)\n\nglimpse(weather_data_imputed)\n\nRows: 25,258\nColumns: 15\n$ Station                   &lt;chr&gt; \"Changi\", \"Changi\", \"Changi\", \"Changi\", \"Cha…\n$ Date                      &lt;date&gt; 2014-01-01, 2014-01-02, 2014-01-03, 2014-01…\n$ Year                      &lt;fct&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014, 20…\n$ Month                     &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Day                       &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1…\n$ Daily.Rainfall.Total..mm. &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 18.4, 31.2, 0.0, 0.0, 2.…\n$ Mean.Temperature...C.     &lt;dbl&gt; 26.7, 27.4, 27.1, 27.1, 24.8, 25.3, 26.7, 27…\n$ Maximum.Temperature...C.  &lt;dbl&gt; 29.0, 30.9, 30.4, 31.1, 26.4, 27.1, 30.7, 31…\n$ Minimum.Temperature...C.  &lt;dbl&gt; 24.9, 25.0, 24.9, 24.9, 23.3, 23.9, 24.3, 24…\n$ Latitude                  &lt;dbl&gt; 1.3678, 1.3678, 1.3678, 1.3678, 1.3678, 1.36…\n$ Longitude                 &lt;dbl&gt; 103.9826, 103.9826, 103.9826, 103.9826, 103.…\n$ Date_mine                 &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-03, 2023-01…\n$ Month_Name                &lt;fct&gt; January, January, January, January, January,…\n$ Week                      &lt;dbl&gt; 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,…\n$ Weekday                   &lt;dbl&gt; 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4,…\n\n\n\nkable(unique(weather_data_imputed$Station),\n      row.names = TRUE,\n      col.names = \"Station\",\n      caption = \"List of Stations\")\n\n\nList of Stations\n\n\n\nStation\n\n\n\n\n1\nChangi\n\n\n2\nChoa Chu Kang (South)\n\n\n3\nEast Coast Parkway\n\n\n4\nJurong (West)\n\n\n5\nNewton\n\n\n6\nPasir Panjang\n\n\n7\nTai Seng\n\n\n\n\n\n\n\nView dataset as interactive table\n\ndatatable(weather_data_imputed, \n            class= \"compact\",\n            rownames = FALSE,\n            width=\"100%\", \n            options = list(pageLength = 10, scrollX=T),\n          caption = 'Cleaned and imputed weather dataset')\n\n\n\n\n\n\n\ncolnames(weather_data_imputed)[6] &lt;- \"Daily_Rainfall_Total_mm\"\ncolnames(weather_data_imputed)[7] &lt;- \"Mean_Temperature\"\ncolnames(weather_data_imputed)[8] &lt;- \"Max_Temperature\"\ncolnames(weather_data_imputed)[9] &lt;- \"Min_Temperature\""
  },
  {
    "objectID": "prototyping/eda.html#cda-hypothesis",
    "href": "prototyping/eda.html#cda-hypothesis",
    "title": "EDA",
    "section": "5.2 CDA Hypothesis",
    "text": "5.2 CDA Hypothesis\nThis confirmatory data analysis section will check the data based on the certain hypothesis made from the exploratory & descriptive analysis in the above sections.\nAs of now, two hypothesis are made:\n\nDoes Singapore’s weather change across different years shows statistical significant?\ncan we clearly identify the ‘dry’ and ‘wet’ month?\n\n\n5.2.1Does Singapore’s Weather Change Across Different Years Shows Statistical Significant?\nIn this part, the weather change accounts for both the temperature and the rainfall as given in the data used.\n\n5.2.1.1 Temperature\n\ntemp_year1 &lt;- weather_data_imputed %&gt;%\n  group_by(Station,Year) %&gt;%\n  summarise(median_mean_temp = median(Mean_Temperature),\n            median_max_temp = median(Max_Temperature),\n            median_min_temp = median(Min_Temperature))\n\nDT::datatable(temp_year1,class = \"compact\")\n\n\n\n\n\n\n\nglimpse(temp_year1)\n\nRows: 70\nColumns: 5\nGroups: Station [7]\n$ Station          &lt;chr&gt; \"Changi\", \"Changi\", \"Changi\", \"Changi\", \"Changi\", \"Ch…\n$ Year             &lt;fct&gt; 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022,…\n$ median_mean_temp &lt;dbl&gt; 28.00, 28.40, 28.60, 27.70, 27.90, 28.60, 28.10, 28.0…\n$ median_max_temp  &lt;dbl&gt; 31.9, 32.0, 32.1, 31.3, 31.9, 32.6, 31.9, 32.1, 31.8,…\n$ median_min_temp  &lt;dbl&gt; 25.20, 25.80, 25.90, 25.10, 25.40, 26.00, 25.40, 25.2…\n\n\nSave the output as csv:\n\nwrite_csv(temp_year1, \"data/temp_year1.csv\")\n\nTo check out the median mean, max and min temperature:\n\nMedian Daily Mean TemperatureMedian Daily MAX TemperatureMedian Daily MIN Temperature\n\n\n\nplot_list &lt;- lapply(unique(temp_year1$Station), function(stn) {\n  station_data &lt;- subset(temp_year1, Station == stn)\n  \n  plot_ly(data = station_data, x = ~Year, y = ~median_mean_temp, name = stn, type = 'scatter', mode = 'lines',\n          hoverinfo = 'text', text = ~paste(\"Station:\", stn, \"&lt;br&gt;Year:\", Year, \"&lt;br&gt;Temp:\", median_mean_temp)) %&gt;%\n    layout(title = paste(\"Median Mean Temperature - Station:\", stn),\n           xaxis = list(title = \"Year\"),\n           yaxis = list(title = \"Temperature (°C)\"))\n})\n\np2 &lt;- subplot(plot_list, nrows = length(unique(temp_year1$Station)), shareX = TRUE, titleX = FALSE)\n\np2 &lt;- layout(p2,\n                       title = \"Median Daily Mean Temperature Across Weather Stations (2014-2023)\",\n                       xaxis = list(tickangle = 90),\n                       margin = list(b = 80)) # Increase bottom margin to accommodate angled x-axis labels\np2\n\n\n\n\n\nBased on the line graph, we can not say that there the mean temperature across selected weather stations have significant changes from year 2014 to 2023.\n\n\n\nplot_list &lt;- lapply(unique(temp_year1$Station), function(stn) {\n  station_data &lt;- subset(temp_year1, Station == stn)\n  \n  plot_ly(data = station_data, x = ~Year, y = ~median_max_temp, name = stn, type = 'scatter', mode = 'lines',\n          hoverinfo = 'text', text = ~paste(\"Station:\", stn, \"&lt;br&gt;Year:\", Year, \"&lt;br&gt;Temp:\", median_max_temp)) %&gt;%\n    layout(title = paste(\"Median Max Temperature - Station:\", stn),\n           xaxis = list(title = \"Year\"),\n           yaxis = list(title = \"Temperature (°C)\"))\n})\n\np3 &lt;- subplot(plot_list, nrows = length(unique(temp_year1$Station)), shareX = TRUE, titleX = FALSE)\n\np3 &lt;- layout(p3,\n                       title = \"Median Daily Maximum Temperature Across Weather Stations (2014-2023)\",\n                       xaxis = list(tickangle = 90),\n                       margin = list(b = 80)) # Increase bottom margin to accommodate angled x-axis labels\np3\n\n\n\n\n\n\n\n\np4 &lt;- lapply(unique(temp_year1$Station), function(stn) {\n  station_data &lt;- subset(temp_year1, Station == stn)\n  \n  plot_ly(data = station_data, x = ~Year, y = ~median_min_temp, name = stn, type = 'scatter', mode = 'lines',\n          hoverinfo = 'text', text = ~paste(\"Station:\", stn, \"&lt;br&gt;Year:\", Year, \"&lt;br&gt;Temp:\", median_min_temp)) %&gt;%\n    layout(title = paste(\"Median Min Temperature - Station:\", stn),\n           xaxis = list(title = \"Year\"),\n           yaxis = list(title = \"Temperature (°C)\"))\n})\n\np4 &lt;- subplot(p4, nrows = length(unique(temp_year1$Station)), shareX = TRUE, titleX = FALSE)\n\np4 &lt;- layout(p4,\n                       title = \"Median Daily Minimum Temperature Across Weather Stations (2014-2023)\",\n                       xaxis = list(tickangle = 90),\n                       margin = list(b = 80)) # Increase bottom margin to accommodate angled x-axis labels\np4\n\n\n\n\n\n\n\n\nBefore performing statistical test on the significant level, is best to determine how the temperature data is distributed in the data. We can observe the normality of the data using ridgeline plots, using the code chunk below:\n\nNormality Daily Mean TemperatureNormality Daily Max TemperatureNormality Daily Min Temperature\n\n\n\np5 &lt;- ggplot(weather_data_imputed, \n       aes(x = Mean_Temperature, \n           y = as.factor(Year), \n           fill = 0.5 - abs(0.5 - ..ecdf..))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\") +\n  facet_wrap(~Station, scales = \"free_y\") + \n  theme_ridges(font_size = 12) + # Adjusted for smaller text\n  coord_cartesian(xlim = c(0,50)) +\n  labs(title=\"Distribution of Mean Temperature from 2014 to 2023\",\n       y=\"Station\",\n       x=\"Mean Temperature (°C)\")\n\np5\n\n\n\n\nBased on the above observation, as the mean temperature is not normally distributed, non-parametric test will be used.\n\n\n\np6 &lt;- ggplot(weather_data_imputed, \n       aes(x = Max_Temperature, \n           y = as.factor(Year), \n           fill = 0.5 - abs(0.5 - ..ecdf..))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\")+\n  facet_wrap(~Station, scales = \"free_y\") + \n  theme_ridges(font_size = 12)+\n  coord_cartesian(xlim = c(0,50))+\n  labs(title=\"Distribution of Maximum Temperature from 2014 to 2023\",\n       y=\"Station\",\n       x=\"Maximum Temperature (°C)\")\n\np6\n\n\n\n\nBased on the above observation, as the maximum temperature is not normally distributed, non-parametric test will be used.\n\n\n\np8 &lt;- ggplot(weather_data_imputed, \n       aes(x = Min_Temperature, \n           y = as.factor(Year), \n           fill = 0.5 - abs(0.5 - ..ecdf..))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\")+\n  facet_wrap(~Station, scales = \"free_y\") + \n  theme_ridges(font_size = 12)+\n  coord_cartesian(xlim = c(0,50))+\n  labs(title=\"Distribution of Minimum Temperature from 2014 to 2023\",\n       y=\"Station\",\n       x=\"Minimum Temperature (°C)\")\n\np8\n\n\n\n\nBased on the above observation, as the minimum temperature is not normally distributed, non-parametric test will be used.\n\n\n\nDefault Non-Parametric tests temperature different per year:\n\nMedian Mean temperature Per YearMedian Max temperature Per YearMedian Min temperature Per Year\n\n\nThe hypothesis is as follows:\nH0: There is no statistical difference between yearly median mean temperature from 2014-2023.\nH1: There is statistical difference between yearly median mean temperature from 2014-2023.\n\np9 &lt;- ggbetweenstats(\n  data = temp_year1,\n  x = Year, \n  y = median_mean_temp,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Yearly Median Mean Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np9\n\n\n\n\nKruskal-Wallis Test: The test has a x^2 value of 19.82 and a p-value of 0.02, which is below the conventional alpha level of 0.05. This suggests that there is statistically significant difference in median maximum temperatures across the years.\n\n\nThe hypothesis is as follows:\nH0: There is no statistical difference between yearly median max temperature from 2014-2023.\nH1: There is statistical difference between yearly median max temperature from 2014-2023.\n\np10 &lt;- ggbetweenstats(\n  data = temp_year1,\n  x = Year, \n  y = median_max_temp,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Yearly Median Maximum Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np10\n\n\n\n\nKruskal-Wallis Test: The test has a x^2 value of 10.02 and a p-value of 0.35, which is above the conventional alpha level of 0.05. This suggests that there is no statistically significant difference in median maximum temperatures across the years. But from yearly difference we can further dig into the daily difference to see if there is a statistical difference.\n\n\nThe hypothesis is as follows:\nH0: There is no statistical difference between yearly median min temperature from 2014-2023.\nH1: There is statistical difference between yearly median min temperature from 2014-2023.\n\np11 &lt;- ggbetweenstats(\n  data = temp_year1,\n  x = Year, \n  y = median_min_temp,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Yearly Median Minimum Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np11\n\n\n\n\nKruskal-Wallis Test: The test has a x^2 value of 14.72 and a p-value of 0.10, which is above the conventional alpha level of 0.05. This suggests that there is no statistically significant difference in median maximum temperatures across the years. But from yearly difference we can further dig into the daily difference to see if there is a statistical difference.\n\n\n\n\nDaily Mean temperatureDaily Max temperatureDaily Min temperature\n\n\nHypothesis :\nH0: There is no statistical difference in daily mean temperature from 2014-2023.\nH1: There is statistical difference in daily mean temperature from 2014-2023.\n\np12 &lt;- ggbetweenstats(\n  data = weather_data_imputed,\n  x = Year, \n  y = Mean_Temperature,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Daily Minimum Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np12\n\n\n\n\n\n\nHypothesis :\nH0: There is no statistical difference in daily max temperature from 2014-2023.\nH1: There is statistical difference in daily max temperature from 2014-2023.\n\np13 &lt;- ggbetweenstats(\n  data = weather_data_imputed,\n  x = Year, \n  y = Max_Temperature,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Daily Maximum Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np13\n\n\n\n\n\n\nHypothesis :\nH0: There is no statistical difference in daily min temperature from 2014-2023.\nH1: There is statistical difference in daily min temperature from 2014-2023.\n\np14 &lt;- ggbetweenstats(\n  data = weather_data_imputed,\n  x = Year, \n  y = Min_Temperature,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Daily Minimum Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np14\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAll daily temperatures (mean, maximum and minimum) have p-value lower than 0.05 which means they all shows statistical significant. Meaning there are statistical different in the mean, maximum and minimum daily temperature in Singapore.\n\nEven though the yearly median max temperature and median min temperature appears no statistical significant, but the daily max and min are statistically different.\n\n\n\n\n\n5.2.1.2 Rainfall\nFor rainfall we will be using the daily rainfall total to test the hypothesis\n\nrainfall_year &lt;- weather_data_imputed %&gt;%\n  group_by(Station,Year) %&gt;%\n  summarise(yearly_rainfall = sum(Daily_Rainfall_Total_mm))\n\nDT::datatable(rainfall_year,class = \"compact\")\n\n\n\n\n\n\n\nwrite_csv(rainfall_year, \"data/rainfall_year.csv\")\n\n\nplot_list &lt;- lapply(unique(rainfall_year$Station), function(stn) {\n  station_data &lt;- subset(rainfall_year, Station == stn)\n  \n  plot_ly(data = station_data, x = ~Year, y = ~yearly_rainfall, name = stn, type = 'scatter', mode = 'lines') %&gt;%\n    layout(title = paste(\"Yearly Rainfall - Station:\", stn),\n           xaxis = list(title = \"Year\", tickangle = 90),\n           yaxis = list(title = \"Rainfall Volume (mm)\"))\n})\n\nfaceted_plot &lt;- subplot(plot_list, nrows = length(unique(rainfall_year$Station)), shareX = TRUE, titleX = FALSE)\n\nfaceted_plot &lt;- layout(faceted_plot,\n                       title = \"Yearly Rainfall Across Weather Stations (2014-2023)\")\nfaceted_plot\n\n\n\n\n\nFrom the observations above, over the pass 10 years from 2014 to 2023 the total rainfall for Singapore captured by different stations indicates there is a volume increase. And every a few years it tend to drop to a low point(2015 and 2019) and will bounce back with even higher volume.\nWe have to check if the different in years of the total rainfall are statistically different, before making any conclusions. But first lets see if the data follows a normal distribution or not in determine the method for test later.\n\np7 &lt;- ggplot(weather_data_imputed, \n       aes(x = Daily_Rainfall_Total_mm, \n           y = as.factor(Year), \n           fill = 0.5 - abs(0.5 - ..ecdf..))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\")+\n  facet_wrap(~Station) + \n  theme_ridges(font_size = 12)+\n  coord_cartesian(xlim = c(0,50))+\n  labs(title=\"Distribution of Daily Rainfall from 2014 to 2023\",\n       y=\"Station\",\n       x=\"Rainfall Volume (mm)\")\n\np7\n\n\n\n\nFrom the distribution graph using sstat function called stat_density_ridges()of ggplot2. We can see that the rainfall distribution is not normally distributed, so non-parametric test will be used.\n\nMedian Rainfall Per YearMedian Daily Rainfall 2014-2023\n\n\nHypothesis:\nH0: There is no statistical difference between median rainfall per year from 2014-2023.\nH1: There is statistical difference between median rainfall per year across 2014-2023.\n\np8 &lt;- ggbetweenstats(\n  data = rainfall_year,\n  x = Year, \n  y = yearly_rainfall,\n  type = \"np\",\n  pairwise.display = \"non-significant\",\n  messages = FALSE,\n  title=\"Distribution of Rainfall from 2014 to 2023\",\n  ylab = \"Rainfall volume (mm)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12), plot.title=element_text(size=12))\n\np8\n\n\n\n\n\n# Filter the data for a specific year\nrainfall_year_filtered &lt;- rainfall_year %&gt;%\n  filter(Year &gt;= 2014, Year &lt;= 2023)\n\n# Create the plotly violin plot\np8_plotly &lt;- plot_ly(data = rainfall_year_filtered,\n                     x = ~Year,\n                     y = ~yearly_rainfall,\n                     type = 'violin',\n                     spanmode = 'hard',\n                     marker = list(opacity = 0.5, line = list(width = 2)),\n                     box = list(visible = T),\n                     points = 'all',\n                     scalemode = 'count',\n                     meanline = list(visible = T, color = \"red\"),\n                     color = I('#caced8'),\n                     marker = list(line = list(width = 2, color = '#caced8'))\n                    ) %&gt;%\n  layout(title = \"Distribution of Rainfall from 2014 to 2023\",\n         yaxis = list(title = \"Rainfall volume (mm)\"),\n         xaxis = list(title = \"Year\"))\n\n# Show the plot\np8_plotly\n\n\n\n\n\nKruskal-Wallis test result at the top indicates a significant difference in rainfall distribution across the years (p-value &lt; 0.01), suggesting that at least one year has a statistically different total rainfall volume compared to the others.\nfrom the lines connecting the years we can observe that some years trend towards significance when the pHolm-adj is less than 1.00. Hence we can reject the null hypothesis and say that the rainfall over the years is statistically significant.\n\n\nHypothesis:\nH0: There is no statistical difference between median daily rainfall from 2014-2023.\nH1: There is statistical difference between median daily rainfall from 2014-2023.\n\np9 &lt;- ggbetweenstats(\n  data = weather_data_imputed,\n  x = Year, \n  y = Daily_Rainfall_Total_mm,\n  type = \"np\",\n  pairwise.display = \"non-significant\",\n  messages = FALSE,\n  title=\"Distribution of Rainfall from 2014 to 2023\",\n  ylab = \"Rainfall volume (mm)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12), plot.title=element_text(size=12))\n\np9\n\n\n\n\nWe can dig further into the daily rainfall total to see if there is statistical significant. After undergo the test above, we can observe the test result that overall Kruskal-Wallis test is highly significant (p=2.84e−89), indicating there are differences in the distributions of daily rainfall volumes across the years.\nWe can also observe that some years the median daily rainfall is 0.00 or 0.20 (2014, 2015, 2019, etc.) suggesting low rainfall volume.\n\n\n\n\n\n\n5.2.2 Can We Clearly Identify the ‘Dry’ and ‘Wet’ Month?\nSingapore which is a tropical country, means have no clear identification of the four seasons, but there are certain months which the ‘cooler’ compare to some months. In this section we will be testing the hypothesis on ‘can we clearly identify the ’Dry’ and ‘Wet’ Month’?\nFirst we need to filter the data to get monthly records, code chunk below:\n\nrf_data_month &lt;- weather_data_imputed %&gt;%\n  group_by(Year,Month) %&gt;%\n  summarise(monthly_rainfall = sum(Daily_Rainfall_Total_mm))\n\nrf_data_month$Year &lt;- factor(rf_data_month$Year)\nrf_data_month$Month &lt;- factor(rf_data_month$Month, levels = as.character(1:12))\n\nDT::datatable(rf_data_month,class = \"compact\")\n\n\n\n\n\n\n\nglimpse(rf_data_month)\n\nRows: 120\nColumns: 3\nGroups: Year [10]\n$ Year             &lt;fct&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014,…\n$ Month            &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5,…\n$ monthly_rainfall &lt;dbl&gt; 450.6, 124.0, 728.1, 1296.2, 1621.8, 1026.9, 1070.8, …\n\n\n\ntemp_month &lt;- weather_data_imputed %&gt;%\n  group_by(Year,Month) %&gt;%\n  summarise(median_mean_temp = median(Mean_Temperature),\n            median_max_temp = median(Max_Temperature),\n            median_min_temp = median(Min_Temperature))\n\nDT::datatable(temp_month,class = \"compact\")\n\n\n\n\n\n\nTo see the distribution of the monthly rainfall and Temperature, code chunk below:\n\nDistribution of Monthly RainfallDistribution of Monthly Mean TemperatureDistribution of Monthly Max TemperatureDistribution of Monthly Min Temperature\n\n\n\ncolor_palette &lt;- brewer.pal(\"Set3\", n = length(unique(rf_data_month$Year)))\n\np18 &lt;- ggplot(rf_data_month, aes(x = Month, y = monthly_rainfall, fill = Year)) +\n  geom_bar(stat = \"identity\") +\n  facet_wrap(~Year, scales = \"free_x\") +\n  labs(title = \"Monthly Rainfall From Year 2014 to 2023\",\n       y = \"Rainfall volume (mm)\",\n       x = \"Month\") +\n  theme_minimal() +\n  scale_fill_manual(values = color_palette) +\n  theme(panel.spacing.y = unit(0.5, \"lines\")) # Adjusted for less spacing\n\np18\n\n\n\n\nFrom the distribution of monthly rainfall from year 2014 to 2023, we can observe that the data is not normally distributed, hence non-parametric test will be used later.\n\n\n\np19 &lt;- ggplot(temp_month,\n       aes(y = median_mean_temp,\n           x = Month,\n           colour = Year)) +\n  geom_line(size = 1.5)+\n  facet_wrap(~Year, scales = \"free_x\") +\n  labs(title=\"Monthly mean Temperature From 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Month\")+\n  coord_cartesian(ylim = c(20,35))+\n  scale_x_discrete(limits = 1:12) + # Assuming Month is numeric already\n  theme_minimal() +\n  theme(panel.spacing.y = unit(0.5,\"lines\"))\n\np19\n\n\n\n\nFrom the distribution of monthly mean temperature from year 2014 to 2023, we can observe that the data is not normally distributed, hence non-parametric test will be used later.\n\n\n\np20 &lt;- ggplot(temp_month,\n       aes(y = median_max_temp,\n           x = Month,\n           colour = Year)) +\n  geom_line(size = 1.5)+\n  facet_wrap(~Year, scales = \"free_x\") +\n  labs(title=\"Monthly Maximum Temperature From 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Month\")+\n  coord_cartesian(ylim = c(20,35))+\n  scale_x_discrete(limits = 1:12) + # Assuming Month is numeric already\n  theme_minimal() +\n  theme(panel.spacing.y = unit(0.5,\"lines\"))\n\np20\n\n\n\n\nFrom the distribution of monthly maximum temperature from year 2014 to 2023, we can observe that the data is not normally distributed, hence non-parametric test will be used later.\n\n\n\np21 &lt;- ggplot(temp_month,\n       aes(y = median_min_temp,\n           x = Month,\n           colour = Year)) +\n  geom_line(size = 1.5)+\n  facet_wrap(~Year, scales = \"free_x\") +\n  labs(title=\"Monthly Minimum Temperature From 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Month\")+\n  coord_cartesian(ylim = c(20,35))+\n  scale_x_discrete(limits = 1:12) + # Assuming Month is numeric already\n  theme_minimal() +\n  theme(panel.spacing.y = unit(0.5,\"lines\"))\n\np21\n\n\n\n\nFrom the distribution of monthly minimum temperature from year 2014 to 2023, we can observe that the data is not normally distributed, hence non-parametric test will be used later.\n\n\n\n\n5.2.2.1 Hypothesis testing\nTo test Monthly Rainfall From Year 2014 to 2023:\nThe hypothesis is as follows:\nH0: There is no statistical difference between minimum temperature across months.\nH1: There is statistical difference between minimum temperature across months.\n\nMonthly Rainfall over yearsMonthly Mean TemperatureMonthly Maximum TemperatureMonthly Minimum Temperature\n\n\nHypothesis:\nH0: There is no statistical difference in rainfall volume across months.\nH1: There is statistical difference in rainfall volume across months.\n\np22 &lt;- ggbetweenstats(\n  data = rf_data_month,\n  x = Month, \n  y = monthly_rainfall,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Rainfall across months 2014 to 2023\",\n  ylab = \"Rainfall volume (mm)\",\n  xlab = \"Month\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12), plot.title=element_text(size=12))\np22\n\n\n\n\nAt CI of 95%, the Kruskal-Wallis test results give a p-value &lt; 0.05, which indicates there is statistical difference in the rainfall volume across different month in Singapore.\n\nFeb has significant different in rainfall volume comparing with Nov and Dec.\n2, 3, 7, 8, 9, 10 can consider ‘Dry’ as median rainfall volume lower or equal to around 1000mm per month.\n4, 5, 6, 11, 12 can consider a ‘Wet’ as median rainfall volume mainly higher than 1400mm per month.\n\n\n\nHypothesis:\nH0: There is no statistical difference between mean temperature across months.\nH1: There is statistical difference between mean temperature across months.\n\np23 &lt;- ggbetweenstats(data = temp_month,\n                      x = Month,\n                      y = median_mean_temp,\n                      type = \"np\",\n                      messages = FALSE,\n                      title = \"Distribution of Mean Temperature by month from 2014 to 2023\",\n                      ylab = \"Temperature (C)\",\n                      xlab = \"Month\",\n                      ggsignif.args = list(textsize =4)) +\n  theme(text = element_text(size = 11),plot.title = element_text(size = 11))\np23\n\n\n\n\nAt CI of 95%, the Kruskal-Wallis test results give a p-value &lt; 0.05, which indicates there is statistical difference in the mean temperature across different month in Singapore.\n\nIt is observed that towards the middle of the 12 months, 5, 6, 7 ,8 ,9 has the highest median mean temperature .\nWhile months 1, 2, 11, 12 has the lowest median mean temperature.\n\n\n\nHypothesis:\nH0: There is no statistical difference between maximum temperature across months.\nH1: There is statistical difference between maximum temperature across months.\n\np24 &lt;- ggbetweenstats(data = temp_month,\n                      x = Month,\n                      y = median_max_temp,\n                      type = \"np\",\n                      messages = FALSE,\n                      title = \"Distribution of Maximum Temperature by month from 2014 to 2023\",\n                      ylab = \"Temperature (C)\",\n                      xlab = \"Month\",\n                      ggsignif.args = list(textsize =4)) +\n  theme(text = element_text(size = 11),plot.title = element_text(size = 11))\np24\n\n\n\n\nAt CI of 95%, the Kruskal-Wallis test results give a p-value &lt; 0.05, which indicates there is statistical difference in the maximum temperature across different month in Singapore.\n\nThe month with highest daily temperature is month 3, 4, 5 which average maximum temperature more than 32 Degree Celsius.\nMonth with lowest daily temperature is January, with only average maximum temperature of 30.85 Degree Celsius.\n\n\n\nHypothesis:\nH0: There is no statistical difference between minimum temperature across months.\nH1: There is statistical difference between minimum temperature across months.\n\np25 &lt;- ggbetweenstats(data = temp_month,\n                      x = Month,\n                      y = median_min_temp,\n                      type = \"np\",\n                      messages = FALSE,\n                      title = \"Distribution of Minimum Temperature by month from 2014 to 2023\",\n                      ylab = \"Temperature (C)\",\n                      xlab = \"Month\",\n                      ggsignif.args = list(textsize =4)) +\n  theme(text = element_text(size = 11),plot.title = element_text(size = 11))\np25\n\n\n\n\nAt CI of 95%, the Kruskal-Wallis test results give a p-value &lt; 0.05, which indicates there is statistical difference in the minimum temperature across different month in Singapore.\n\n\n\nFrom the hypothesis testing, result indicates that we can clearly identify the ‘Dry’ or ‘Wet’ months, and also the ‘Hot’ and ‘Cool’ months from the date used.\nFrom the hypothesis testing, several result can be shown:\n\nDry Month: 2, 3, 7, 8, 9\nWet Month :1, 6, 11, 12\nHot Month: 3, 4, 5, 9, 10\nCool Month: 1, 2, 11, 12\nDry & Hot : 3, 9\nWet & Cool : 1, 11, 12\n\nBy identifying this can help Singapore Government to develop strategies to deal with different situations, and also to see the trend in future if there is shift in different type of month"
  },
  {
    "objectID": "prototyping/forecast.html",
    "href": "prototyping/forecast.html",
    "title": "Untitled",
    "section": "",
    "text": "This exercise serves as a prototype for one of the modules, i.e. the nowcasting / forecasting models, used in the group’s proposed Shiny application for the Visual Analytics Project. Prototyping of the Shiny App has the following benefits:\n\nValidate the feasibility and effectiveness of your ideas or analytical approaches\nGather feedback from stakeholders or end-users early in the development process\nIteratively update the prototype, adding new features, improving usability, and refining visualizations until the desired outcome is achieved\nFacilitates collaboration among team members or stakeholders\nIdentify and address potential issues early in the development process\n\n\n\n\nAs part of this prototyping exercise, the following objectives are fulfilled:\n\nIdentified and evaluated the necessary R packages in R CRAN\nPrepared and tested the R codes for the models\nDetermined the parameters and outputs that will be exposed on the Shiny applications\nSelected the appropriate Shiny UI components for exposing the parameters\n\n\n\n\nForecasting Singapore’s private housing index is beset with difficulties, arising from the complex interplay among several factors such as economic indicators, employment trends, policy changes, and current market sentiments. The intricacy is further intensified by the delayed nature of crucial indices and indicators, which are commonly released with a substantial time delay, usually spanning from one to three months. These delays impede the capacity to accurately predict private house price changes, as the most up-to-date data required for precise forecasts is not easily accessible.\nTo tackle this problem, it is necessary to utlilise nowcasting models that can precisely forecast the future direction of the Singapore private housing market. The objective is to utilize these models to provide stakeholders, including homebuyers, sellers, investors, and policy makers, with timely and convenient access to predictive data via visual analytics."
  },
  {
    "objectID": "prototyping/forecast.html#setting-the-scene",
    "href": "prototyping/forecast.html#setting-the-scene",
    "title": "Untitled",
    "section": "",
    "text": "This exercise serves as a prototype for one of the modules, i.e. the nowcasting / forecasting models, used in the group’s proposed Shiny application for the Visual Analytics Project. Prototyping of the Shiny App has the following benefits:\n\nValidate the feasibility and effectiveness of your ideas or analytical approaches\nGather feedback from stakeholders or end-users early in the development process\nIteratively update the prototype, adding new features, improving usability, and refining visualizations until the desired outcome is achieved\nFacilitates collaboration among team members or stakeholders\nIdentify and address potential issues early in the development process"
  },
  {
    "objectID": "prototyping/forecast.html#the-task",
    "href": "prototyping/forecast.html#the-task",
    "title": "Untitled",
    "section": "",
    "text": "As part of this prototyping exercise, the following objectives are fulfilled:\n\nIdentified and evaluated the necessary R packages in R CRAN\nPrepared and tested the R codes for the models\nDetermined the parameters and outputs that will be exposed on the Shiny applications\nSelected the appropriate Shiny UI components for exposing the parameters"
  },
  {
    "objectID": "prototyping/forecast.html#problem-statement-of-group-project",
    "href": "prototyping/forecast.html#problem-statement-of-group-project",
    "title": "Untitled",
    "section": "",
    "text": "Forecasting Singapore’s private housing index is beset with difficulties, arising from the complex interplay among several factors such as economic indicators, employment trends, policy changes, and current market sentiments. The intricacy is further intensified by the delayed nature of crucial indices and indicators, which are commonly released with a substantial time delay, usually spanning from one to three months. These delays impede the capacity to accurately predict private house price changes, as the most up-to-date data required for precise forecasts is not easily accessible.\nTo tackle this problem, it is necessary to utlilise nowcasting models that can precisely forecast the future direction of the Singapore private housing market. The objective is to utilize these models to provide stakeholders, including homebuyers, sellers, investors, and policy makers, with timely and convenient access to predictive data via visual analytics."
  },
  {
    "objectID": "prototyping/forecast.html#loading-r-packages",
    "href": "prototyping/forecast.html#loading-r-packages",
    "title": "Untitled",
    "section": "2.1 Loading R packages",
    "text": "2.1 Loading R packages\nThe pacman::p_load() function is used to install and load the required R packages into the R environment, as below.\n\ntidyverse: collection of R packages designed for data science\nrandomForest: an R library for classification and regression based on a forest of trees using random inputs\nplotly: an R graphing library for plotting interactive, publication-quality graphs\ngbm: an R library for Freund and Schapire’s AdaBoost algorithm and Friedman’s gradient boosting machine\nprophet: an R library that implements a procedure for forecasting time series data based on an additive model developed by Facebook\nknitr: an R package for dynamic report generation\npatchwork: an R package for preparing composite figure created using ggplot2\n\n\npacman::p_load(tidyverse, randomForest, plotly, gbm, prophet, knitr, patchwork,tidyverse, naniar, imputeTS, DT, knitr, lubridate,\n               ggplot2, patchwork, ggthemes,\n               tseries, ggHoriPlot,dplyr,\n               TSclust, fable, dtwclust, dendextend,\n               ggraph, plotly, factoextra, ggdendrosf,terra,gstat,tmap,viridis,tidyverse,dplyr)\n\nInstalling package into 'C:/Users/Yizao/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: package 'ggdendrosf' is not available for this version of R\n\nA version of this package for your version of R might be available elsewhere,\nsee the ideas at\nhttps://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\nWarning: 'BiocManager' not available.  Could not check Bioconductor.\n\nPlease use `install.packages('BiocManager')` and then retry.\n\n\nWarning in p_install(package, character.only = TRUE, ...):\n\n\nWarning in library(package, lib.loc = lib.loc, character.only = TRUE,\nlogical.return = TRUE, : there is no package called 'ggdendrosf'\n\n\nInstalling package into 'C:/Users/Yizao/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\nWarning: unable to access index for repository http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3:\n  cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/4.3/PACKAGES'\n\n\npackage 'tmap' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\Yizao\\AppData\\Local\\Temp\\RtmpshQDXZ\\downloaded_packages\n\n\n\ntmap installed\n\n\nWarning: package 'tmap' was built under R version 4.3.3\n\n\nWarning in pacman::p_load(tidyverse, randomForest, plotly, gbm, prophet, : Failed to install/load:\nggdendrosf, tmap\n\n\n\nweather_data_imputed &lt;- read.csv('data/weather_data_imputed.csv')"
  },
  {
    "objectID": "prototyping/forecast.html#prototype-of-random-forest-model",
    "href": "prototyping/forecast.html#prototype-of-random-forest-model",
    "title": "Untitled",
    "section": "3.2 Prototype of Random Forest model",
    "text": "3.2 Prototype of Random Forest model\nThe prototype uses randomForest() of the randomForest package to model the property price index using explanatory variable for forecasting, to make predictions on the subsequent periods based on new / unseen data.\n\n# Load the necessary libraries if not already loaded\nlibrary(dplyr)\n\n# Define the cutoff year\ncut_off_year &lt;- 2018\n\n# Define the explanatory variables (you will need to replace this with your actual variables)\nexplanatory_vars &lt;- c(\"Month\", \"Day\", \"Mean_Temperature\", \"Max_Temperature\", \"Min_Temperature\")\n\n# Define the dependent variable (replace 'PropertyPriceIndex' with your actual dependent variable)\ndependent_var &lt;- \"Daily_Rainfall_Total_mm\"\n\n# Convert Date to a numeric year format for filtering\nweather_data_imputed$Year &lt;- as.numeric(format(as.Date(weather_data_imputed$Date), \"%Y\"))\n\n# Split the dataset into training and testing sets\nweather_rf_train &lt;- subset(weather_data_imputed, Year &lt; cut_off_year) %&gt;%\n  select(all_of(explanatory_vars), all_of(dependent_var)) %&gt;%\n  na.omit()\n\nweather_rf_test &lt;- subset(weather_data_imputed, Year &gt;= cut_off_year) %&gt;%\n  select(all_of(explanatory_vars), all_of(dependent_var)) %&gt;%\n  na.omit()\n\n# View the structure of the training and testing sets\nstr(weather_rf_train)\n\n'data.frame':   9921 obs. of  6 variables:\n $ Month                  : int  1 1 1 1 1 1 1 1 1 1 ...\n $ Day                    : int  1 2 3 4 5 6 7 8 9 10 ...\n $ Mean_Temperature       : num  26.7 27.4 27.1 27.1 24.8 25.3 26.7 27.1 25.9 26.8 ...\n $ Max_Temperature        : num  29 30.9 30.4 31.1 26.4 27.1 30.7 31.8 29.3 30.6 ...\n $ Min_Temperature        : num  24.9 25 24.9 24.9 23.3 23.9 24.3 24.7 24.3 24.2 ...\n $ Daily_Rainfall_Total_mm: num  0 0 0 0 18.4 31.2 0 0 2 0 ...\n\nstr(weather_rf_test)\n\n'data.frame':   15337 obs. of  6 variables:\n $ Month                  : int  1 1 1 1 1 1 1 1 1 1 ...\n $ Day                    : int  1 2 3 4 5 6 7 8 9 10 ...\n $ Mean_Temperature       : num  24.8 25.5 26.6 26.1 26 26.8 26.8 26.4 27.2 24.5 ...\n $ Max_Temperature        : num  26.7 27.3 31.1 28.2 29 29.7 30.5 30.3 31.4 26.7 ...\n $ Min_Temperature        : num  23.6 24.3 24.1 25 24.8 24.4 24.2 23.4 25.2 22.8 ...\n $ Daily_Rainfall_Total_mm: num  32.2 0.8 2 0.2 1 0 0 45.8 1.8 29.8 ...\n\n\nThe code chunk below shows the preparation of the dataset based on user selected inputs, including the partitioning of the dataset into training and testing datasets based on the user selected year to start forecasting from.\n\n# Define user-selected model parameters\nntree &lt;- 500    # Replace with user-selected value for number of trees\nmtry &lt;- 3       # Replace with user-selected value for number of variables tried at each split\nnodesize &lt;- 5   # Replace with user-selected value for minimum size of terminal nodes\n\n# Train the Random Forest model using the training data\n# 'dependent_var' should be replaced with the actual name of your dependent variable column\nrf_model &lt;- randomForest(Daily_Rainfall_Total_mm ~ ., data = weather_rf_train, ntree = ntree, mtry = mtry, nodesize = nodesize, importance = TRUE, na.action = na.omit)\n\n# View the model summary\nprint(rf_model)\n\n\nCall:\n randomForest(formula = Daily_Rainfall_Total_mm ~ ., data = weather_rf_train,      ntree = ntree, mtry = mtry, nodesize = nodesize, importance = TRUE,      na.action = na.omit) \n               Type of random forest: regression\n                     Number of trees: 500\nNo. of variables tried at each split: 3\n\n          Mean of squared residuals: 76.7478\n                    % Var explained: 44.85\n\n# View variable importance\nimportance(rf_model)\n\n                   %IncMSE IncNodePurity\nMonth             67.53066      164583.2\nDay               37.83141      182733.4\nMean_Temperature  42.29005      214658.7\nMax_Temperature   53.82814      215712.0\nMin_Temperature  151.02226      492932.0\n\n\nThe code chunk below uses randomForest() to create the model using the training dataset with the user selected model parameters.\n\n# Predictions and performance metrics\npredictions_train &lt;- predict(rf_model, newdata = weather_rf_train)\nrmse_train &lt;- sqrt(mean((weather_rf_train$Daily_Rainfall_Total_mm - predictions_train)^2))\nmae_train &lt;- mean(abs(weather_rf_train$Daily_Rainfall_Total_mm - predictions_train))\n\npredictions_test &lt;- predict(rf_model, newdata = weather_rf_test)\nrmse_test &lt;- sqrt(mean((weather_rf_test$Daily_Rainfall_Total_mm - predictions_test)^2))\nmae_test &lt;- mean(abs(weather_rf_test$Daily_Rainfall_Total_mm - predictions_test))\n\n# Combine the performance metrics into a data frame\nperformance_metrics &lt;- data.frame(\n  Error = c('RMSE', 'MAE'),\n  Train = c(rmse_train, mae_train),\n  Test = c(rmse_test, mae_test)\n)\n\n\n# 表 1 实际值与预测值和残差\n# Combine actual and predicted values for train and test sets\nresults &lt;- data.frame(Actual = weather_rf_test$Daily_Rainfall_Total_mm, Predicted = predictions_test, DataPartition = \"Test\")\ntrain_results &lt;- data.frame(Actual = weather_rf_train$Daily_Rainfall_Total_mm, Predicted = predictions_train, DataPartition = \"Train\") %&gt;%\n  bind_rows(results)\n\n# Plot for actual vs predicted values\np_actual_vs_predicted &lt;- ggplot(data = train_results, aes(x = Actual, y = Predicted, color = DataPartition)) +\n  geom_abline(intercept = 0, slope = 1, color = \"red\", linetype = \"dashed\") +\n  geom_point(alpha = 0.5) +\n  labs(x = \"Actual\", y = \"Predicted\", title = \"Actual vs. Predicted Values\") +\n  theme_bw()\n\n# Plot for residuals\ntrain_results$Residuals &lt;- train_results$Actual - train_results$Predicted\np_residuals &lt;- ggplot(data=train_results, aes(x=Predicted, y=Residuals, colour = DataPartition)) +\n  geom_point() +\n  geom_hline(yintercept=0, color = 'red', linetype = 'dashed') +\n  labs(title = \"Residual Plot\") +\n  theme_bw()\n\n# Print the plots (you can also save them using ggsave())\nprint(p_actual_vs_predicted)\n\n\n\nprint(p_residuals)\n\n\n\n\n\n# 表 2 变量重要性\n# Get the importance matrix and convert it to a data frame\nimportance_data &lt;- as.data.frame(importance(rf_model))\nnames(importance_data)  # This should print the correct column names\n\n[1] \"%IncMSE\"       \"IncNodePurity\"\n\n# The correct column names are \"%IncMSE\" and \"IncNodePurity\"\n# Now we will plot using the correct names\np_importance &lt;- ggplot(importance_data, aes(x = row.names(importance_data), y = IncNodePurity)) +\n  geom_bar(stat=\"identity\") +\n  theme_bw() +\n  labs(x = \"Variables\", y = \"Increase in Node Purity\", title = \"Variable Importance\") +\n  coord_flip() # Flips the axes for a horizontal plot\n\nprint(p_importance)\n\n\n\n\n\n# 表3 时间序列预测\n# Create a 'Date' column for weather_rf_train, assuming the year 2021 for simplicity.\nweather_rf_train$Date &lt;- as.Date(paste('2021', as.character(weather_rf_train$Month), as.character(weather_rf_train$Day), sep='-'), format='%Y-%m-%d')\n\n# Assuming the length of predictions_test matches the number of rows in weather_rf_test\nweather_rf_test$Year &lt;- rep(2021, nrow(weather_rf_test))  # Replace with the actual year(s) if necessary\nweather_rf_test$Date &lt;- as.Date(paste(weather_rf_test$Year, weather_rf_test$Month, weather_rf_test$Day, sep=\"-\"), format=\"%Y-%m-%d\")\n\n# Ensure the 'Date' column is not empty\nif(length(weather_rf_test$Date) == 0) {\n  stop(\"The 'Date' column in 'weather_rf_test' is empty.\")\n}\n\n# Assuming predictions_test and weather_rf_test$Date have been verified to be of equal length, create the results data frame.\nresults &lt;- data.frame(Date = weather_rf_test$Date, Predicted = predictions_test, Actual = weather_rf_test$Daily_Rainfall_Total_mm)\n\n# Now plot the time series\np_time_series &lt;- ggplot() +\n  geom_line(data = weather_rf_train, aes(x = Date, y = Daily_Rainfall_Total_mm), color = \"green\", size = 0.7) +\n  geom_line(data = results, aes(x = Date, y = Predicted), color = \"blue\", linetype = \"dotted\", size = 0.7) +\n  labs(y = \"Rainfall (mm)\", x = \"Date\", title = \"Time Series of Rainfall (Actual in green, Predicted in blue)\") +\n  theme_bw()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n# Print the time series plot\nprint(p_time_series)\n\nWarning: Removed 7 rows containing missing values or values outside the scale range\n(`geom_line()`).\n\n\nWarning: Removed 7 rows containing missing values or values outside the scale range\n(`geom_line()`)."
  },
  {
    "objectID": "prototyping/intro_proto.html",
    "href": "prototyping/intro_proto.html",
    "title": "Prototype Introduction",
    "section": "",
    "text": "1  Overview\nFor this Take Home Exercise, there are several task needs to be done to create the Shiny application.\n\nTo evaluate and determine the necessary R packages needed for your Shiny application are supported in R CRAN,\nTo prepare and test the specific R codes can be run and returned the correct output as expected,\nTo determine the parameters and outputs that will be exposed on the Shiny applications, and\nTo select the appropriate Shiny UI components for exposing the parameters determine above.\n\nThis submission includes the prototype report for the group project, which will includes:\n\nthe data preparation process,\nthe selection of data visualisation techniques used,\nand the data visualisation design and interactivity principles and best practices implemented.\n\n\n\n2  Project Infomation\nThe purpose of this project is to create a Shiny app with user-friendly interface and functions, and also create a website for user to discover the historical Weather changes in Singapore.\nThe Prototype R Shiny app:\n\nHomepage: An introduction page to give an overview on the data set and also visuals for user to interact with.\nExploratory Data Analysis: In this tab user can explore the basic distribution of the data set based on the input they set.\nTime series analysis: The data is in time series by years, user can select the years that they want to explore\nClustering time series analysis: Users can explore grouping stations with similar weather patterns or grouping time periods with similar patterns. The user would then be able to choose different models to forecast the grouped data."
  },
  {
    "objectID": "prototyping/Project.html",
    "href": "prototyping/Project.html",
    "title": "EDA",
    "section": "",
    "text": "For this Take Home Exercise, there are several task needs to be done to create the Shiny application.\n\nTo evaluate and determine the necessary R packages needed for your Shiny application are supported in R CRAN,\nTo prepare and test the specific R codes can be run and returned the correct output as expected,\nTo determine the parameters and outputs that will be exposed on the Shiny applications, and\nTo select the appropriate Shiny UI components for exposing the parameters determine above.\n\nThis submission includes the prototype report for the group project, which will includes:\n\nthe data preparation process,\nthe selection of data visualization techniques used,\nand the data visualization design and interactivity principles and best practices implemented.\n\nBased on the discussion with team member i will be focusing on the Exploratory Data Analysis & Confirmatory Data Analysis, and the UI design for our Shiny app."
  },
  {
    "objectID": "prototyping/Project.html#check-structure-with-glimpse",
    "href": "prototyping/Project.html#check-structure-with-glimpse",
    "title": "EDA",
    "section": "4.1 Check structure with glimpse()",
    "text": "4.1 Check structure with glimpse()\n\nglimpse(raw_weather_data)\n\nRows: 204,464\nColumns: 15\n$ Station                       &lt;chr&gt; \"Paya Lebar\", \"Paya Lebar\", \"Paya Lebar\"…\n$ Year                          &lt;int&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014…\n$ Month                         &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ Day                           &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1…\n$ Daily.Rainfall.Total..mm.     &lt;chr&gt; \"0\", \"0\", \"2.2\", \"0.6\", \"10.5\", \"31.2\", …\n$ Highest.30.min.Rainfall..mm.  &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", …\n$ Highest.60.min.Rainfall..mm.  &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", …\n$ Highest.120.min.Rainfall..mm. &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", …\n$ Mean.Temperature...C.         &lt;chr&gt; \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", \"�\", …\n$ Maximum.Temperature...C.      &lt;chr&gt; \"29.5\", \"31.7\", \"31.1\", \"32.3\", \"27\", \"2…\n$ Minimum.Temperature...C.      &lt;chr&gt; \"24.8\", \"25\", \"25.1\", \"23.7\", \"23.8\", \"2…\n$ Mean.Wind.Speed..km.h.        &lt;chr&gt; \"15.8\", \"16.5\", \"14.9\", \"8.9\", \"11.9\", \"…\n$ Max.Wind.Speed..km.h.         &lt;chr&gt; \"35.3\", \"37.1\", \"33.5\", \"35.3\", \"33.5\", …\n$ Latitude                      &lt;dbl&gt; 1.3524, 1.3524, 1.3524, 1.3524, 1.3524, …\n$ Longitude                     &lt;dbl&gt; 103.9007, 103.9007, 103.9007, 103.9007, …\n\n\nThere are 204464 rows, and 15 columns in the dataset. We see that there are missing values shown as ‘?’ in the dataset. In the next few steps, we will drop specific columns and rows based on the project focus."
  },
  {
    "objectID": "prototyping/Project.html#drop-unused-columns",
    "href": "prototyping/Project.html#drop-unused-columns",
    "title": "EDA",
    "section": "4.2 Drop unused columns",
    "text": "4.2 Drop unused columns\nWe will not be using all 15 columns for this project. The following columns will be dropped:\n\nHighest 30 Min Rainfall (mm)\nHighest 60 Min Rainfall (mm)\nHighest 1200 Min Rainfall (mm)\nMean Wind Speed (km/h)\nMax Wind Speed (km/h)\n\n\nraw_weather_data &lt;- raw_weather_data %&gt;%\n  select(-c(`Highest.30.min.Rainfall..mm.`, \n            `Highest.60.min.Rainfall..mm.`, \n            `Highest.120.min.Rainfall..mm.`,\n            `Mean.Wind.Speed..km.h.`,\n            `Max.Wind.Speed..km.h.`))"
  },
  {
    "objectID": "prototyping/Project.html#remove-rows-for-specific-stations",
    "href": "prototyping/Project.html#remove-rows-for-specific-stations",
    "title": "EDA",
    "section": "4.3 Remove rows for specific Stations",
    "text": "4.3 Remove rows for specific Stations\nThe Meteorological Service Singapore also provides a file, Station Records that has some information on the availability of data for each station. After examining the station records file, we found that 41 stations had missing information for some variables. We will hence drop rows for these stations.\n\n# Drop rows of 41 stations\n# Define the station names to remove\nstations_to_remove &lt;- c(\"Macritchie Reservoir\", \"Lower Peirce Reservoir\", \"Pasir Ris (West)\", \"Kampong Bahru\", \"Jurong Pier\", \"Ulu Pandan\", \"Serangoon\", \"Jurong (East)\", \"Mandai\", \"Upper Thomson\", \"Buangkok\", \"Boon Lay (West)\", \"Bukit Panjang\", \"Kranji Reservoir\", \"Tanjong Pagar\", \"Admiralty West\", \"Queenstown\", \"Tanjong Katong\", \"Chai Chee\", \"Upper Peirce Reservoir\", \"Kent Ridge\", \"Somerset (Road)\", \"Punggol\", \"Tuas West\", \"Simei\", \"Toa Payoh\", \"Tuas\", \"Bukit Timah\", \"Yishun\", \"Buona Vista\", \"Pasir Ris (Central)\", \"Jurong (North)\", \"Choa Chu Kang (West)\", \"Serangoon North\", \"Lim Chu Kang\", \"Marine Parade\", \"Choa Chu Kang (Central)\", \"Dhoby Ghaut\", \"Nicoll Highway\", \"Botanic Garden\", \"Whampoa\")\n\n# Remove rows with the specified station names\nraw_weather_data &lt;- raw_weather_data[!raw_weather_data$Station %in% stations_to_remove, ]\n\n# Print the number of stations left\nprint(sprintf(\" %d stations removed. %d stations left.\", length(stations_to_remove), n_distinct(raw_weather_data$Station)))\n\n[1] \" 41 stations removed. 22 stations left.\""
  },
  {
    "objectID": "prototyping/Project.html#check-for-duplicates",
    "href": "prototyping/Project.html#check-for-duplicates",
    "title": "EDA",
    "section": "4.4 Check for duplicates",
    "text": "4.4 Check for duplicates\n\n# Identify duplicates\nduplicates &lt;- raw_weather_data[duplicated(raw_weather_data[c(\"Station\", \"Year\", \"Month\", \"Day\")]) | duplicated(raw_weather_data[c(\"Station\", \"Year\", \"Month\", \"Day\")], fromLast = TRUE), ]\n\n# Check if 'duplicates' dataframe is empty\nif (nrow(duplicates) == 0) {\n  print(\"The combination of Station Name, Year, Month, and Day is unique.\")\n} else {\n  print(\"There are duplicates in the combination of Station Name, Year, Month, and Day. Showing duplicated rows:\")\n  print(duplicates)\n}\n\n[1] \"There are duplicates in the combination of Station Name, Year, Month, and Day. Showing duplicated rows:\"\n               Station Year Month Day Daily.Rainfall.Total..mm.\n13381   Semakau Island   NA    NA  NA                         -\n13382   Semakau Island   NA    NA  NA                         -\n13383   Semakau Island   NA    NA  NA                         -\n13384   Semakau Island   NA    NA  NA                         -\n13385   Semakau Island   NA    NA  NA                         -\n13386   Semakau Island   NA    NA  NA                         -\n13387   Semakau Island   NA    NA  NA                         -\n13388   Semakau Island   NA    NA  NA                         -\n13389   Semakau Island   NA    NA  NA                         -\n13390   Semakau Island   NA    NA  NA                         -\n13391   Semakau Island   NA    NA  NA                         -\n13392   Semakau Island   NA    NA  NA                         -\n13393   Semakau Island   NA    NA  NA                         -\n13394   Semakau Island   NA    NA  NA                         -\n13395   Semakau Island   NA    NA  NA                         -\n13396   Semakau Island   NA    NA  NA                         -\n13397   Semakau Island   NA    NA  NA                         -\n13398   Semakau Island   NA    NA  NA                         -\n13399   Semakau Island   NA    NA  NA                         -\n13400   Semakau Island   NA    NA  NA                         -\n13401   Semakau Island   NA    NA  NA                         -\n13402   Semakau Island   NA    NA  NA                         -\n13403   Semakau Island   NA    NA  NA                         -\n13404   Semakau Island   NA    NA  NA                         -\n13405   Semakau Island   NA    NA  NA                         -\n13406   Semakau Island   NA    NA  NA                         -\n13407   Semakau Island   NA    NA  NA                         -\n13408   Semakau Island   NA    NA  NA                         -\n13409   Semakau Island   NA    NA  NA                         -\n13410   Semakau Island   NA    NA  NA                         -\n13411   Semakau Island   NA    NA  NA                         -\n13412   Semakau Island   NA    NA  NA                         -\n13413   Semakau Island   NA    NA  NA                         -\n13414   Semakau Island   NA    NA  NA                         -\n13415   Semakau Island   NA    NA  NA                         -\n13416   Semakau Island   NA    NA  NA                         -\n13417   Semakau Island   NA    NA  NA                         -\n13418   Semakau Island   NA    NA  NA                         -\n13419   Semakau Island   NA    NA  NA                         -\n13420   Semakau Island   NA    NA  NA                         -\n13421   Semakau Island   NA    NA  NA                         -\n13422   Semakau Island   NA    NA  NA                         -\n13423   Semakau Island   NA    NA  NA                         -\n13424   Semakau Island   NA    NA  NA                         -\n13425   Semakau Island   NA    NA  NA                         -\n13426   Semakau Island   NA    NA  NA                         -\n13427   Semakau Island   NA    NA  NA                         -\n13428   Semakau Island   NA    NA  NA                         -\n13429   Semakau Island   NA    NA  NA                         -\n13430   Semakau Island   NA    NA  NA                         -\n13431   Semakau Island   NA    NA  NA                         -\n13432   Semakau Island   NA    NA  NA                         -\n13433   Semakau Island   NA    NA  NA                         -\n13434   Semakau Island   NA    NA  NA                         -\n13435   Semakau Island   NA    NA  NA                         -\n13436   Semakau Island   NA    NA  NA                         -\n13437   Semakau Island   NA    NA  NA                         -\n13438   Semakau Island   NA    NA  NA                         -\n13439   Semakau Island   NA    NA  NA                         -\n13440   Semakau Island   NA    NA  NA                         -\n13441   Semakau Island   NA    NA  NA                         -\n14084   Semakau Island   NA    NA  NA                         -\n14085   Semakau Island   NA    NA  NA                         -\n14086   Semakau Island   NA    NA  NA                         -\n14087   Semakau Island   NA    NA  NA                         -\n14088   Semakau Island   NA    NA  NA                         -\n183829 Boon Lay (East)   NA    NA  NA                         -\n183830 Boon Lay (East)   NA    NA  NA                         -\n183831 Boon Lay (East)   NA    NA  NA                         -\n183832 Boon Lay (East)   NA    NA  NA                         -\n183833 Boon Lay (East)   NA    NA  NA                         -\n183834 Boon Lay (East)   NA    NA  NA                         -\n183835 Boon Lay (East)   NA    NA  NA                         -\n183836 Boon Lay (East)   NA    NA  NA                         -\n183837 Boon Lay (East)   NA    NA  NA                         -\n183838 Boon Lay (East)   NA    NA  NA                         -\n183839 Boon Lay (East)   NA    NA  NA                         -\n183840 Boon Lay (East)   NA    NA  NA                         -\n183841 Boon Lay (East)   NA    NA  NA                         -\n183842 Boon Lay (East)   NA    NA  NA                         -\n183843 Boon Lay (East)   NA    NA  NA                         -\n183844 Boon Lay (East)   NA    NA  NA                         -\n183845 Boon Lay (East)   NA    NA  NA                         -\n183846 Boon Lay (East)   NA    NA  NA                         -\n183847 Boon Lay (East)   NA    NA  NA                         -\n183848 Boon Lay (East)   NA    NA  NA                         -\n183849 Boon Lay (East)   NA    NA  NA                         -\n183850 Boon Lay (East)   NA    NA  NA                         -\n183851 Boon Lay (East)   NA    NA  NA                         -\n183852 Boon Lay (East)   NA    NA  NA                         -\n183853 Boon Lay (East)   NA    NA  NA                         -\n183854 Boon Lay (East)   NA    NA  NA                         -\n183855 Boon Lay (East)   NA    NA  NA                         -\n183856 Boon Lay (East)   NA    NA  NA                         -\n183857 Boon Lay (East)   NA    NA  NA                         -\n183858 Boon Lay (East)   NA    NA  NA                         -\n191071 Boon Lay (East)   NA    NA  NA                         -\n191072 Boon Lay (East)   NA    NA  NA                         -\n191073 Boon Lay (East)   NA    NA  NA                         -\n191074 Boon Lay (East)   NA    NA  NA                         -\n191075 Boon Lay (East)   NA    NA  NA                         -\n191076 Boon Lay (East)   NA    NA  NA                         -\n191077 Boon Lay (East)   NA    NA  NA                         -\n191078 Boon Lay (East)   NA    NA  NA                         -\n191079 Boon Lay (East)   NA    NA  NA                         -\n191080 Boon Lay (East)   NA    NA  NA                         -\n191081 Boon Lay (East)   NA    NA  NA                         -\n191082 Boon Lay (East)   NA    NA  NA                         -\n191083 Boon Lay (East)   NA    NA  NA                         -\n191084 Boon Lay (East)   NA    NA  NA                         -\n191085 Boon Lay (East)   NA    NA  NA                         -\n191086 Boon Lay (East)   NA    NA  NA                         -\n191087 Boon Lay (East)   NA    NA  NA                         -\n191088 Boon Lay (East)   NA    NA  NA                         -\n191089 Boon Lay (East)   NA    NA  NA                         -\n191090 Boon Lay (East)   NA    NA  NA                         -\n191091 Boon Lay (East)   NA    NA  NA                         -\n191092 Boon Lay (East)   NA    NA  NA                         -\n191093 Boon Lay (East)   NA    NA  NA                         -\n191094 Boon Lay (East)   NA    NA  NA                         -\n191095 Boon Lay (East)   NA    NA  NA                         -\n191096 Boon Lay (East)   NA    NA  NA                         -\n191097 Boon Lay (East)   NA    NA  NA                         -\n191098 Boon Lay (East)   NA    NA  NA                         -\n191099 Boon Lay (East)   NA    NA  NA                         -\n191100 Boon Lay (East)   NA    NA  NA                         -\n191101 Boon Lay (East)   NA    NA  NA                         -\n       Mean.Temperature...C. Maximum.Temperature...C. Minimum.Temperature...C.\n13381                      -                        -                        -\n13382                      -                        -                        -\n13383                      -                        -                        -\n13384                      -                        -                        -\n13385                      -                        -                        -\n13386                      -                        -                        -\n13387                      -                        -                        -\n13388                      -                        -                        -\n13389                      -                        -                        -\n13390                      -                        -                        -\n13391                      -                        -                        -\n13392                      -                        -                        -\n13393                      -                        -                        -\n13394                      -                        -                        -\n13395                      -                        -                        -\n13396                      -                        -                        -\n13397                      -                        -                        -\n13398                      -                        -                        -\n13399                      -                        -                        -\n13400                      -                        -                        -\n13401                      -                        -                        -\n13402                      -                        -                        -\n13403                      -                        -                        -\n13404                      -                        -                        -\n13405                      -                        -                        -\n13406                      -                        -                        -\n13407                      -                        -                        -\n13408                      -                        -                        -\n13409                      -                        -                        -\n13410                      -                        -                        -\n13411                      -                        -                        -\n13412                      -                        -                        -\n13413                      -                        -                        -\n13414                      -                        -                        -\n13415                      -                        -                        -\n13416                      -                        -                        -\n13417                      -                        -                        -\n13418                      -                        -                        -\n13419                      -                        -                        -\n13420                      -                        -                        -\n13421                      -                        -                        -\n13422                      -                        -                        -\n13423                      -                        -                        -\n13424                      -                        -                        -\n13425                      -                        -                        -\n13426                      -                        -                        -\n13427                      -                        -                        -\n13428                      -                        -                        -\n13429                      -                        -                        -\n13430                      -                        -                        -\n13431                      -                        -                        -\n13432                      -                        -                        -\n13433                      -                        -                        -\n13434                      -                        -                        -\n13435                      -                        -                        -\n13436                      -                        -                        -\n13437                      -                        -                        -\n13438                      -                        -                        -\n13439                      -                        -                        -\n13440                      -                        -                        -\n13441                      -                        -                        -\n14084                      -                        -                        -\n14085                      -                        -                        -\n14086                      -                        -                        -\n14087                      -                        -                        -\n14088                      -                        -                        -\n183829                     -                        -                        -\n183830                     -                        -                        -\n183831                     -                        -                        -\n183832                     -                        -                        -\n183833                     -                        -                        -\n183834                     -                        -                        -\n183835                     -                        -                        -\n183836                     -                        -                        -\n183837                     -                        -                        -\n183838                     -                        -                        -\n183839                     -                        -                        -\n183840                     -                        -                        -\n183841                     -                        -                        -\n183842                     -                        -                        -\n183843                     -                        -                        -\n183844                     -                        -                        -\n183845                     -                        -                        -\n183846                     -                        -                        -\n183847                     -                        -                        -\n183848                     -                        -                        -\n183849                     -                        -                        -\n183850                     -                        -                        -\n183851                     -                        -                        -\n183852                     -                        -                        -\n183853                     -                        -                        -\n183854                     -                        -                        -\n183855                     -                        -                        -\n183856                     -                        -                        -\n183857                     -                        -                        -\n183858                     -                        -                        -\n191071                     -                        -                        -\n191072                     -                        -                        -\n191073                     -                        -                        -\n191074                     -                        -                        -\n191075                     -                        -                        -\n191076                     -                        -                        -\n191077                     -                        -                        -\n191078                     -                        -                        -\n191079                     -                        -                        -\n191080                     -                        -                        -\n191081                     -                        -                        -\n191082                     -                        -                        -\n191083                     -                        -                        -\n191084                     -                        -                        -\n191085                     -                        -                        -\n191086                     -                        -                        -\n191087                     -                        -                        -\n191088                     -                        -                        -\n191089                     -                        -                        -\n191090                     -                        -                        -\n191091                     -                        -                        -\n191092                     -                        -                        -\n191093                     -                        -                        -\n191094                     -                        -                        -\n191095                     -                        -                        -\n191096                     -                        -                        -\n191097                     -                        -                        -\n191098                     -                        -                        -\n191099                     -                        -                        -\n191100                     -                        -                        -\n191101                     -                        -                        -\n       Latitude Longitude\n13381    1.1890  103.7680\n13382    1.1890  103.7680\n13383    1.1890  103.7680\n13384    1.1890  103.7680\n13385    1.1890  103.7680\n13386    1.1890  103.7680\n13387    1.1890  103.7680\n13388    1.1890  103.7680\n13389    1.1890  103.7680\n13390    1.1890  103.7680\n13391    1.1890  103.7680\n13392    1.1890  103.7680\n13393    1.1890  103.7680\n13394    1.1890  103.7680\n13395    1.1890  103.7680\n13396    1.1890  103.7680\n13397    1.1890  103.7680\n13398    1.1890  103.7680\n13399    1.1890  103.7680\n13400    1.1890  103.7680\n13401    1.1890  103.7680\n13402    1.1890  103.7680\n13403    1.1890  103.7680\n13404    1.1890  103.7680\n13405    1.1890  103.7680\n13406    1.1890  103.7680\n13407    1.1890  103.7680\n13408    1.1890  103.7680\n13409    1.1890  103.7680\n13410    1.1890  103.7680\n13411    1.1890  103.7680\n13412    1.1890  103.7680\n13413    1.1890  103.7680\n13414    1.1890  103.7680\n13415    1.1890  103.7680\n13416    1.1890  103.7680\n13417    1.1890  103.7680\n13418    1.1890  103.7680\n13419    1.1890  103.7680\n13420    1.1890  103.7680\n13421    1.1890  103.7680\n13422    1.1890  103.7680\n13423    1.1890  103.7680\n13424    1.1890  103.7680\n13425    1.1890  103.7680\n13426    1.1890  103.7680\n13427    1.1890  103.7680\n13428    1.1890  103.7680\n13429    1.1890  103.7680\n13430    1.1890  103.7680\n13431    1.1890  103.7680\n13432    1.1890  103.7680\n13433    1.1890  103.7680\n13434    1.1890  103.7680\n13435    1.1890  103.7680\n13436    1.1890  103.7680\n13437    1.1890  103.7680\n13438    1.1890  103.7680\n13439    1.1890  103.7680\n13440    1.1890  103.7680\n13441    1.1890  103.7680\n14084    1.1890  103.7680\n14085    1.1890  103.7680\n14086    1.1890  103.7680\n14087    1.1890  103.7680\n14088    1.1890  103.7680\n183829   1.3302  103.7205\n183830   1.3302  103.7205\n183831   1.3302  103.7205\n183832   1.3302  103.7205\n183833   1.3302  103.7205\n183834   1.3302  103.7205\n183835   1.3302  103.7205\n183836   1.3302  103.7205\n183837   1.3302  103.7205\n183838   1.3302  103.7205\n183839   1.3302  103.7205\n183840   1.3302  103.7205\n183841   1.3302  103.7205\n183842   1.3302  103.7205\n183843   1.3302  103.7205\n183844   1.3302  103.7205\n183845   1.3302  103.7205\n183846   1.3302  103.7205\n183847   1.3302  103.7205\n183848   1.3302  103.7205\n183849   1.3302  103.7205\n183850   1.3302  103.7205\n183851   1.3302  103.7205\n183852   1.3302  103.7205\n183853   1.3302  103.7205\n183854   1.3302  103.7205\n183855   1.3302  103.7205\n183856   1.3302  103.7205\n183857   1.3302  103.7205\n183858   1.3302  103.7205\n191071   1.3302  103.7205\n191072   1.3302  103.7205\n191073   1.3302  103.7205\n191074   1.3302  103.7205\n191075   1.3302  103.7205\n191076   1.3302  103.7205\n191077   1.3302  103.7205\n191078   1.3302  103.7205\n191079   1.3302  103.7205\n191080   1.3302  103.7205\n191081   1.3302  103.7205\n191082   1.3302  103.7205\n191083   1.3302  103.7205\n191084   1.3302  103.7205\n191085   1.3302  103.7205\n191086   1.3302  103.7205\n191087   1.3302  103.7205\n191088   1.3302  103.7205\n191089   1.3302  103.7205\n191090   1.3302  103.7205\n191091   1.3302  103.7205\n191092   1.3302  103.7205\n191093   1.3302  103.7205\n191094   1.3302  103.7205\n191095   1.3302  103.7205\n191096   1.3302  103.7205\n191097   1.3302  103.7205\n191098   1.3302  103.7205\n191099   1.3302  103.7205\n191100   1.3302  103.7205\n191101   1.3302  103.7205"
  },
  {
    "objectID": "prototyping/Project.html#check-and-handle-missing-values",
    "href": "prototyping/Project.html#check-and-handle-missing-values",
    "title": "EDA",
    "section": "4.5 Check and handle missing values",
    "text": "4.5 Check and handle missing values\n\n4.5.1 First check for missing values\nMissing values in this dataset can be represented by:\n\n\\u0097\nNA\n-\n\nWe first replace these values with actual NA values:\n\nraw_weather_data &lt;- raw_weather_data %&gt;%\n  mutate(across(where(is.character), ~na_if(.x, \"\\u0097\"))) %&gt;%\n  mutate(across(where(is.character), ~na_if(.x, \"NA\"))) %&gt;%\n  mutate(across(where(is.character), ~na_if(.x, \"-\")))\n\nNext, we visualize the missing values in the dataset:\n\n# For a simple missing data plot\ngg_miss_var(raw_weather_data)\n\n\n\n\nWe can see there is quite a number of missing data in the Mean Temperature, Minimum Temperature, Maximum Temperature and Daily Rainfall Total. We will take steps to handle the missing data.\n\n\n4.5.2 Remove Stations with significant missing data\nWe have identified two checks to make:\n\nCheck which stations have no recorded data for entire months.\nCheck which stations have more than 7 consecutive days of missing data\n\nFor both these checks, we will remove the entire station from the dataset as it would not be practical to impute such large amounts of missing values.\n\n4.5.3 Identify and remove Stations with no recorded data for entire months\nSome stations have no recorded data for entire months, as summarised in the table below:\n\n# Create complete combination of Station, Year, and Month\nall_combinations &lt;- expand.grid(\n  Station = unique(raw_weather_data$Station),\n  Year = 2021:2023,\n  Month = 1:12\n)\n\n# Left join this with the original weather data to identify missing entries\nmissing_months &lt;- all_combinations %&gt;%\n  left_join(raw_weather_data, by = c(\"Station\", \"Year\", \"Month\")) %&gt;%\n  # Use is.na() to check for rows that didn't have a match in the original data\n  filter(is.na(Day)) %&gt;%\n  # Select only the relevant columns for the final output\n  select(Station, Year, Month)\n\n# Create a summary table that lists out the missing months\nmissing_months_summary &lt;- missing_months %&gt;%\n  group_by(Station, Year) %&gt;%\n  summarise(MissingMonths = toString(sort(unique(Month))), .groups = 'drop')\n\nkable(missing_months_summary)\n\n\n\n\nStation\nYear\nMissingMonths\n\n\n\n\nBoon Lay (East)\n2021\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\nBoon Lay (East)\n2022\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\nBoon Lay (East)\n2023\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\nKhatib\n2022\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\nKhatib\n2023\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\n\n\n\n\n\nWe hence drop these stations from our dataset:\n\nraw_weather_data &lt;- anti_join(raw_weather_data, missing_months, by = \"Station\")\n\nprint(sprintf(\"The folowing %d stations were dropped: %s\", n_distinct(missing_months$Station), paste(unique(missing_months$Station), collapse = \", \")))\n\n[1] \"The folowing 2 stations were dropped: Boon Lay (East), Khatib\"\n\n\n\nprint(sprintf(\"There are %d stations left: \", n_distinct(raw_weather_data$Station)))\n\n[1] \"There are 20 stations left: \"\n\n\n\nkable(unique(raw_weather_data$Station),\n      row.names = TRUE,\n      col.names = \"Station\",\n      caption = \"List of Remaining Stations\")\n\n\nList of Remaining Stations\n\n\n\nStation\n\n\n\n\n1\nPaya Lebar\n\n\n2\nSemakau Island\n\n\n3\nAdmiralty\n\n\n4\nPulau Ubin\n\n\n5\nEast Coast Parkway\n\n\n6\nMarina Barrage\n\n\n7\nAng Mo Kio\n\n\n8\nNewton\n\n\n9\nJurong Island\n\n\n10\nTuas South\n\n\n11\nPasir Panjang\n\n\n12\nChoa Chu Kang (South)\n\n\n13\nTengah\n\n\n14\nChangi\n\n\n15\nSeletar\n\n\n16\nTai Seng\n\n\n17\nJurong (West)\n\n\n18\nClementi\n\n\n19\nSentosa Island\n\n\n20\nSembawang\n\n\n\n\n\n\n\n4.5.4 Identify and remove Stations with excessive missing values\nIf there are any missing values, we can try to impute these missing values. However, if there are 7 or more consecutive values missing, we will remove these stations first.\n\n# Define a helper function to count the number of 7 or more consecutive NAs\ncount_seven_consecutive_NAs &lt;- function(x) {\n  na_runs &lt;- rle(is.na(x))\n  total_consecutive_NAs &lt;- sum(na_runs$lengths[na_runs$values & na_runs$lengths &gt;= 7])\n  return(total_consecutive_NAs)\n}\n\n# Apply the helper function to each relevant column within grouped data\nweather_summary &lt;- raw_weather_data %&gt;%\n  group_by(Station, Year, Month) %&gt;%\n  summarise(across(-Day, ~ count_seven_consecutive_NAs(.x), .names = \"count_consec_NAs_{.col}\"), .groups = \"drop\")\n\n# Filter to keep only rows where there is at least one column with 7 or more consecutive missing values\nweather_summary_with_consecutive_NAs &lt;- weather_summary %&gt;%\n  filter(if_any(starts_with(\"count_consec_NAs_\"), ~ . &gt; 0))\n\n# View the result\nprint(sprintf(\"There are %d stations with 7 or more consecutive missing values.\", n_distinct(weather_summary_with_consecutive_NAs$Station)))\n\n[1] \"There are 13 stations with 7 or more consecutive missing values.\"\n\n\n\n# kable(weather_summary_with_consecutive_NAs)\ndatatable(weather_summary_with_consecutive_NAs, \n            class= \"compact\",\n            rownames = FALSE,\n            width=\"100%\", \n            options = list(pageLength = 10, scrollX=T),\n          caption = 'Details of stations with &gt;=7 missing values')\n\n\n\n\n\n\nWe hence drop these stations from our dataset:\n\nraw_weather_data &lt;- anti_join(raw_weather_data, weather_summary_with_consecutive_NAs, by = \"Station\")\n\nprint(sprintf(\"The folowing %d stations were dropped: %s\", n_distinct(weather_summary_with_consecutive_NAs$Station), paste(unique(weather_summary_with_consecutive_NAs$Station), collapse = \", \")))\n\n[1] \"The folowing 13 stations were dropped: Admiralty, Ang Mo Kio, Clementi, Jurong Island, Marina Barrage, Paya Lebar, Pulau Ubin, Seletar, Semakau Island, Sembawang, Sentosa Island, Tengah, Tuas South\"\n\n\n\nprint(sprintf(\"There are %d stations left: \", n_distinct(raw_weather_data$Station)))\n\n[1] \"There are 7 stations left: \"\n\n\n\nkable(unique(raw_weather_data$Station),\n      row.names = TRUE,\n      col.names = \"Station\",\n      caption = \"List of Remaining Stations\")\n\n\nList of Remaining Stations\n\n\n\nStation\n\n\n\n\n1\nEast Coast Parkway\n\n\n2\nNewton\n\n\n3\nPasir Panjang\n\n\n4\nChoa Chu Kang (South)\n\n\n5\nChangi\n\n\n6\nTai Seng\n\n\n7\nJurong (West)\n\n\n\n\n\n\n\n\n4.5.5 Second check for missing values\nFrom the check below we see there are still missing values in our data. We will impute these values in the next step.\n\n# For a simple missing data plot\ngg_miss_var(raw_weather_data)\n\n\n\n\nWe can see that there is still a few missing values from the selected stations.\n\n\n4.6 Impute missing values\nTo handle the missing values for the remaining Stations, we will impute missing values using simple moving average from imputeTS package.\n\nraw_weather_data &lt;- raw_weather_data %&gt;%\n  mutate(Date = as.Date(paste(Year, Month, Day, sep = \"-\"))) %&gt;%\n  relocate(Date, .after = 1)\n\n\n# Define the weather variables to loop through\nweather_variables &lt;- c(\"Daily.Rainfall.Total..mm.\", \"Mean.Temperature...C.\", \"Maximum.Temperature...C.\", \"Minimum.Temperature...C.\")\n\n# Ensure raw_weather_data is correctly copied to a new data frame for imputation\nweather_data_imputed &lt;- raw_weather_data\n\n# Loop through each weather variable to impute missing values\nfor(variable in weather_variables) {\n  # Convert variable to numeric, ensuring that the conversion warnings are handled if necessary\n  weather_data_imputed[[variable]] &lt;- as.numeric(as.character(weather_data_imputed[[variable]]))\n  \n  # Impute missing values using a moving average\n  weather_data_imputed &lt;- weather_data_imputed %&gt;%\n    group_by(Station) %&gt;%\n    arrange(Station, Date) %&gt;%\n    mutate(\"{variable}\" := round(na_ma(.data[[variable]], k = 7, weighting = \"simple\"), 1)) %&gt;%\n    ungroup()\n}\n\n\n\n4.7 Add specific columns to data [NEW]\nThese columns are added as they may be used in plots later.\n\nweather_data_imputed &lt;- weather_data_imputed %&gt;% \n  mutate(Date_mine = make_date(2023, month(Date), day(Date)),\n         Month_Name = factor(months(Date), levels = month.name),\n         Week = isoweek(Date),\n         Weekday = wday(Date)\n  )"
  },
  {
    "objectID": "prototyping/Project.html#summary-of-cleaned-data",
    "href": "prototyping/Project.html#summary-of-cleaned-data",
    "title": "EDA",
    "section": "4.8 Summary of cleaned data",
    "text": "4.8 Summary of cleaned data\n\nDetails of stations and time period of data\n\ntime_period_start &lt;- min(weather_data_imputed$Date)\ntime_period_end &lt;- max(weather_data_imputed$Date)\ncat(\"\\nThe time period of the dataset is from\", format(time_period_start, \"%Y-%m-%d\"),\"to\", format(time_period_end, \"%Y-%m-%d\"), \"\\n\")\n\n\nThe time period of the dataset is from 2014-01-01 to 2024-01-31 \n\n\nbut i only want to keep until 2023, exclude record in 2024\n\nweather_data_imputed &lt;- subset(weather_data_imputed, Date &lt;= as.Date(\"2023-12-31\"))\n\ntime_period_start &lt;- min(weather_data_imputed$Date)\ntime_period_end &lt;- max(weather_data_imputed$Date)\ncat(\"\\nThe time period of the dataset is from\", format(time_period_start, \"%Y-%m-%d\"),\"to\", format(time_period_end, \"%Y-%m-%d\"), \"\\n\")\n\n\nThe time period of the dataset is from 2014-01-01 to 2023-12-31 \n\n\nAnd also to ease further analysis, convert year, month, day to factor data type:\n\nweather_data_imputed &lt;- weather_data_imputed %&gt;%\n  mutate_at(vars(Year,Month,Day),as.factor)\n\nglimpse(weather_data_imputed)\n\nRows: 25,258\nColumns: 15\n$ Station                   &lt;chr&gt; \"Changi\", \"Changi\", \"Changi\", \"Changi\", \"Cha…\n$ Date                      &lt;date&gt; 2014-01-01, 2014-01-02, 2014-01-03, 2014-01…\n$ Year                      &lt;fct&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014, 20…\n$ Month                     &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ Day                       &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1…\n$ Daily.Rainfall.Total..mm. &lt;dbl&gt; 0.0, 0.0, 0.0, 0.0, 18.4, 31.2, 0.0, 0.0, 2.…\n$ Mean.Temperature...C.     &lt;dbl&gt; 26.7, 27.4, 27.1, 27.1, 24.8, 25.3, 26.7, 27…\n$ Maximum.Temperature...C.  &lt;dbl&gt; 29.0, 30.9, 30.4, 31.1, 26.4, 27.1, 30.7, 31…\n$ Minimum.Temperature...C.  &lt;dbl&gt; 24.9, 25.0, 24.9, 24.9, 23.3, 23.9, 24.3, 24…\n$ Latitude                  &lt;dbl&gt; 1.3678, 1.3678, 1.3678, 1.3678, 1.3678, 1.36…\n$ Longitude                 &lt;dbl&gt; 103.9826, 103.9826, 103.9826, 103.9826, 103.…\n$ Date_mine                 &lt;date&gt; 2023-01-01, 2023-01-02, 2023-01-03, 2023-01…\n$ Month_Name                &lt;fct&gt; January, January, January, January, January,…\n$ Week                      &lt;dbl&gt; 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,…\n$ Weekday                   &lt;dbl&gt; 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4,…\n\n\n\nkable(unique(weather_data_imputed$Station),\n      row.names = TRUE,\n      col.names = \"Station\",\n      caption = \"List of Stations\")\n\n\nList of Stations\n\n\n\nStation\n\n\n\n\n1\nChangi\n\n\n2\nChoa Chu Kang (South)\n\n\n3\nEast Coast Parkway\n\n\n4\nJurong (West)\n\n\n5\nNewton\n\n\n6\nPasir Panjang\n\n\n7\nTai Seng\n\n\n\n\n\n\n\nView dataset as interactive table\n\ndatatable(weather_data_imputed, \n            class= \"compact\",\n            rownames = FALSE,\n            width=\"100%\", \n            options = list(pageLength = 10, scrollX=T),\n          caption = 'Cleaned and imputed weather dataset')\n\n\n\n\n\n\n\ncolnames(weather_data_imputed)[6] &lt;- \"Daily_Rainfall_Total_mm\"\ncolnames(weather_data_imputed)[7] &lt;- \"Mean_Temperature\"\ncolnames(weather_data_imputed)[8] &lt;- \"Max_Temperature\"\ncolnames(weather_data_imputed)[9] &lt;- \"Min_Temperature\""
  },
  {
    "objectID": "prototyping/Project.html#cda-hypothesis",
    "href": "prototyping/Project.html#cda-hypothesis",
    "title": "EDA",
    "section": "5.2 CDA Hypothesis",
    "text": "5.2 CDA Hypothesis\nThis confirmatory data analysis section will check the data based on the certain hypothesis made from the exploratory & descriptive analysis in the above sections.\nAs of now, two hypothesis are made:\n\nDoes Singapore’s weather change across different years shows statistical significant?\ncan we clearly identify the ‘dry’ and ‘wet’ month?\n\n\n5.2.1Does Singapore’s Weather Change Across Different Years Shows Statistical Significant?\nIn this part, the weather change accounts for both the temperature and the rainfall as given in the data used.\n\n5.2.1.1 Temperature\n\ntemp_year1 &lt;- weather_data_imputed %&gt;%\n  group_by(Station,Year) %&gt;%\n  summarise(median_mean_temp = median(Mean_Temperature),\n            median_max_temp = median(Max_Temperature),\n            median_min_temp = median(Min_Temperature))\n\nDT::datatable(temp_year1,class = \"compact\")\n\n\n\n\n\n\n\nglimpse(temp_year1)\n\nRows: 70\nColumns: 5\nGroups: Station [7]\n$ Station          &lt;chr&gt; \"Changi\", \"Changi\", \"Changi\", \"Changi\", \"Changi\", \"Ch…\n$ Year             &lt;fct&gt; 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022,…\n$ median_mean_temp &lt;dbl&gt; 28.00, 28.40, 28.60, 27.70, 27.90, 28.60, 28.10, 28.0…\n$ median_max_temp  &lt;dbl&gt; 31.9, 32.0, 32.1, 31.3, 31.9, 32.6, 31.9, 32.1, 31.8,…\n$ median_min_temp  &lt;dbl&gt; 25.20, 25.80, 25.90, 25.10, 25.40, 26.00, 25.40, 25.2…\n\n\nSave the output as csv:\n\nwrite_csv(temp_year1, \"data/temp_year1.csv\")\n\nTo check out the median mean, max and min temperature:\n\nMedian Daily Mean TemperatureMedian Daily MAX TemperatureMedian Daily MIN Temperature\n\n\n\nplot_list &lt;- lapply(unique(temp_year1$Station), function(stn) {\n  station_data &lt;- subset(temp_year1, Station == stn)\n  \n  plot_ly(data = station_data, x = ~Year, y = ~median_mean_temp, name = stn, type = 'scatter', mode = 'lines',\n          hoverinfo = 'text', text = ~paste(\"Station:\", stn, \"&lt;br&gt;Year:\", Year, \"&lt;br&gt;Temp:\", median_mean_temp)) %&gt;%\n    layout(title = paste(\"Median Mean Temperature - Station:\", stn),\n           xaxis = list(title = \"Year\"),\n           yaxis = list(title = \"Temperature (°C)\"))\n})\n\np2 &lt;- subplot(plot_list, nrows = length(unique(temp_year1$Station)), shareX = TRUE, titleX = FALSE)\n\np2 &lt;- layout(p2,\n                       title = \"Median Daily Mean Temperature Across Weather Stations (2014-2023)\",\n                       xaxis = list(tickangle = 90),\n                       margin = list(b = 80)) # Increase bottom margin to accommodate angled x-axis labels\np2\n\n\n\n\n\nBased on the line graph, we can not say that there the mean temperature across selected weather stations have significant changes from year 2014 to 2023.\n\n\n\nplot_list &lt;- lapply(unique(temp_year1$Station), function(stn) {\n  station_data &lt;- subset(temp_year1, Station == stn)\n  \n  plot_ly(data = station_data, x = ~Year, y = ~median_max_temp, name = stn, type = 'scatter', mode = 'lines',\n          hoverinfo = 'text', text = ~paste(\"Station:\", stn, \"&lt;br&gt;Year:\", Year, \"&lt;br&gt;Temp:\", median_max_temp)) %&gt;%\n    layout(title = paste(\"Median Max Temperature - Station:\", stn),\n           xaxis = list(title = \"Year\"),\n           yaxis = list(title = \"Temperature (°C)\"))\n})\n\np3 &lt;- subplot(plot_list, nrows = length(unique(temp_year1$Station)), shareX = TRUE, titleX = FALSE)\n\np3 &lt;- layout(p3,\n                       title = \"Median Daily Maximum Temperature Across Weather Stations (2014-2023)\",\n                       xaxis = list(tickangle = 90),\n                       margin = list(b = 80)) # Increase bottom margin to accommodate angled x-axis labels\np3\n\n\n\n\n\n\n\n\np4 &lt;- lapply(unique(temp_year1$Station), function(stn) {\n  station_data &lt;- subset(temp_year1, Station == stn)\n  \n  plot_ly(data = station_data, x = ~Year, y = ~median_min_temp, name = stn, type = 'scatter', mode = 'lines',\n          hoverinfo = 'text', text = ~paste(\"Station:\", stn, \"&lt;br&gt;Year:\", Year, \"&lt;br&gt;Temp:\", median_min_temp)) %&gt;%\n    layout(title = paste(\"Median Min Temperature - Station:\", stn),\n           xaxis = list(title = \"Year\"),\n           yaxis = list(title = \"Temperature (°C)\"))\n})\n\np4 &lt;- subplot(p4, nrows = length(unique(temp_year1$Station)), shareX = TRUE, titleX = FALSE)\n\np4 &lt;- layout(p4,\n                       title = \"Median Daily Minimum Temperature Across Weather Stations (2014-2023)\",\n                       xaxis = list(tickangle = 90),\n                       margin = list(b = 80)) # Increase bottom margin to accommodate angled x-axis labels\np4\n\n\n\n\n\n\n\n\nBefore performing statistical test on the significant level, is best to determine how the temperature data is distributed in the data. We can observe the normality of the data using ridgeline plots, using the code chunk below:\n\nNormality Daily Mean TemperatureNormality Daily Max TemperatureNormality Daily Min Temperature\n\n\n\np5 &lt;- ggplot(weather_data_imputed, \n       aes(x = Mean_Temperature, \n           y = as.factor(Year), \n           fill = 0.5 - abs(0.5 - ..ecdf..))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\") +\n  facet_wrap(~Station, scales = \"free_y\") + \n  theme_ridges(font_size = 12) + # Adjusted for smaller text\n  coord_cartesian(xlim = c(0,50)) +\n  labs(title=\"Distribution of Mean Temperature from 2014 to 2023\",\n       y=\"Station\",\n       x=\"Mean Temperature (°C)\")\n\np5\n\n\n\n\nBased on the above observation, as the mean temperature is not normally distributed, non-parametric test will be used.\n\n\n\np6 &lt;- ggplot(weather_data_imputed, \n       aes(x = Max_Temperature, \n           y = as.factor(Year), \n           fill = 0.5 - abs(0.5 - ..ecdf..))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\")+\n  facet_wrap(~Station, scales = \"free_y\") + \n  theme_ridges(font_size = 12)+\n  coord_cartesian(xlim = c(0,50))+\n  labs(title=\"Distribution of Maximum Temperature from 2014 to 2023\",\n       y=\"Station\",\n       x=\"Maximum Temperature (°C)\")\n\np6\n\n\n\n\nBased on the above observation, as the maximum temperature is not normally distributed, non-parametric test will be used.\n\n\n\np8 &lt;- ggplot(weather_data_imputed, \n       aes(x = Min_Temperature, \n           y = as.factor(Year), \n           fill = 0.5 - abs(0.5 - ..ecdf..))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\")+\n  facet_wrap(~Station, scales = \"free_y\") + \n  theme_ridges(font_size = 12)+\n  coord_cartesian(xlim = c(0,50))+\n  labs(title=\"Distribution of Minimum Temperature from 2014 to 2023\",\n       y=\"Station\",\n       x=\"Minimum Temperature (°C)\")\n\np8\n\n\n\n\nBased on the above observation, as the minimum temperature is not normally distributed, non-parametric test will be used.\n\n\n\nDefault Non-Parametric tests temperature different per year:\n\nMedian Mean temperature Per YearMedian Max temperature Per YearMedian Min temperature Per Year\n\n\nThe hypothesis is as follows:\nH0: There is no statistical difference between yearly median mean temperature from 2014-2023.\nH1: There is statistical difference between yearly median mean temperature from 2014-2023.\n\np9 &lt;- ggbetweenstats(\n  data = temp_year1,\n  x = Year, \n  y = median_mean_temp,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Yearly Median Mean Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np9\n\n\n\n\nKruskal-Wallis Test: The test has a x^2 value of 19.82 and a p-value of 0.02, which is below the conventional alpha level of 0.05. This suggests that there is statistically significant difference in median maximum temperatures across the years.\n\n\nThe hypothesis is as follows:\nH0: There is no statistical difference between yearly median max temperature from 2014-2023.\nH1: There is statistical difference between yearly median max temperature from 2014-2023.\n\np10 &lt;- ggbetweenstats(\n  data = temp_year1,\n  x = Year, \n  y = median_max_temp,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Yearly Median Maximum Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np10\n\n\n\n\nKruskal-Wallis Test: The test has a x^2 value of 10.02 and a p-value of 0.35, which is above the conventional alpha level of 0.05. This suggests that there is no statistically significant difference in median maximum temperatures across the years. But from yearly difference we can further dig into the daily difference to see if there is a statistical difference.\n\n\nThe hypothesis is as follows:\nH0: There is no statistical difference between yearly median min temperature from 2014-2023.\nH1: There is statistical difference between yearly median min temperature from 2014-2023.\n\np11 &lt;- ggbetweenstats(\n  data = temp_year1,\n  x = Year, \n  y = median_min_temp,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Yearly Median Minimum Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np11\n\n\n\n\nKruskal-Wallis Test: The test has a x^2 value of 14.72 and a p-value of 0.10, which is above the conventional alpha level of 0.05. This suggests that there is no statistically significant difference in median maximum temperatures across the years. But from yearly difference we can further dig into the daily difference to see if there is a statistical difference.\n\n\n\n\nDaily Mean temperatureDaily Max temperatureDaily Min temperature\n\n\nHypothesis :\nH0: There is no statistical difference in daily mean temperature from 2014-2023.\nH1: There is statistical difference in daily mean temperature from 2014-2023.\n\np12 &lt;- ggbetweenstats(\n  data = weather_data_imputed,\n  x = Year, \n  y = Mean_Temperature,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Daily Minimum Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np12\n\n\n\n\n\n\nHypothesis :\nH0: There is no statistical difference in daily max temperature from 2014-2023.\nH1: There is statistical difference in daily max temperature from 2014-2023.\n\np13 &lt;- ggbetweenstats(\n  data = weather_data_imputed,\n  x = Year, \n  y = Max_Temperature,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Daily Maximum Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np13\n\n\n\n\n\n\nHypothesis :\nH0: There is no statistical difference in daily min temperature from 2014-2023.\nH1: There is statistical difference in daily min temperature from 2014-2023.\n\np14 &lt;- ggbetweenstats(\n  data = weather_data_imputed,\n  x = Year, \n  y = Min_Temperature,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Daily Minimum Temperature from 2014 to 2023\",\n  ylab = \"Temperature (°C)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12),plot.title=element_text(size=12))\np14\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAll daily temperatures (mean, maximum and minimum) have p-value lower than 0.05 which means they all shows statistical significant. Meaning there are statistical different in the mean, maximum and minimum daily temperature in Singapore.\n\nEven though the yearly median max temperature and median min temperature appears no statistical significant, but the daily max and min are statistically different.\n\n\n\n\n\n5.2.1.2 Rainfall\nFor rainfall we will be using the daily rainfall total to test the hypothesis\n\nrainfall_year &lt;- weather_data_imputed %&gt;%\n  group_by(Station,Year) %&gt;%\n  summarise(yearly_rainfall = sum(Daily_Rainfall_Total_mm))\n\nDT::datatable(rainfall_year,class = \"compact\")\n\n\n\n\n\n\n\nwrite_csv(rainfall_year, \"data/rainfall_year.csv\")\n\n\nplot_list &lt;- lapply(unique(rainfall_year$Station), function(stn) {\n  station_data &lt;- subset(rainfall_year, Station == stn)\n  \n  plot_ly(data = station_data, x = ~Year, y = ~yearly_rainfall, name = stn, type = 'scatter', mode = 'lines') %&gt;%\n    layout(title = paste(\"Yearly Rainfall - Station:\", stn),\n           xaxis = list(title = \"Year\", tickangle = 90),\n           yaxis = list(title = \"Rainfall Volume (mm)\"))\n})\n\nfaceted_plot &lt;- subplot(plot_list, nrows = length(unique(rainfall_year$Station)), shareX = TRUE, titleX = FALSE)\n\nfaceted_plot &lt;- layout(faceted_plot,\n                       title = \"Yearly Rainfall Across Weather Stations (2014-2023)\")\nfaceted_plot\n\n\n\n\n\nFrom the observations above, over the pass 10 years from 2014 to 2023 the total rainfall for Singapore captured by different stations indicates there is a volume increase. And every a few years it tend to drop to a low point(2015 and 2019) and will bounce back with even higher volume.\nWe have to check if the different in years of the total rainfall are statistically different, before making any conclusions. But first lets see if the data follows a normal distribution or not in determine the method for test later.\n\np7 &lt;- ggplot(weather_data_imputed, \n       aes(x = Daily_Rainfall_Total_mm, \n           y = as.factor(Year), \n           fill = 0.5 - abs(0.5 - ..ecdf..))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option=\"turbo\")+\n  facet_wrap(~Station) + \n  theme_ridges(font_size = 12)+\n  coord_cartesian(xlim = c(0,50))+\n  labs(title=\"Distribution of Daily Rainfall from 2014 to 2023\",\n       y=\"Station\",\n       x=\"Rainfall Volume (mm)\")\n\np7\n\n\n\n\nFrom the distribution graph using sstat function called stat_density_ridges()of ggplot2. We can see that the rainfall distribution is not normally distributed, so non-parametric test will be used.\n\nMedian Rainfall Per YearMedian Daily Rainfall 2014-2023\n\n\nHypothesis:\nH0: There is no statistical difference between median rainfall per year from 2014-2023.\nH1: There is statistical difference between median rainfall per year across 2014-2023.\n\np8 &lt;- ggbetweenstats(\n  data = rainfall_year,\n  x = Year, \n  y = yearly_rainfall,\n  type = \"np\",\n  pairwise.display = \"non-significant\",\n  messages = FALSE,\n  title=\"Distribution of Rainfall from 2014 to 2023\",\n  ylab = \"Rainfall volume (mm)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12), plot.title=element_text(size=12))\n\np8\n\n\n\n\n\n# Filter the data for a specific year\nrainfall_year_filtered &lt;- rainfall_year %&gt;%\n  filter(Year &gt;= 2014, Year &lt;= 2023)\n\n# Create the plotly violin plot\np8_plotly &lt;- plot_ly(data = rainfall_year_filtered,\n                     x = ~Year,\n                     y = ~yearly_rainfall,\n                     type = 'violin',\n                     spanmode = 'hard',\n                     marker = list(opacity = 0.5, line = list(width = 2)),\n                     box = list(visible = T),\n                     points = 'all',\n                     scalemode = 'count',\n                     meanline = list(visible = T, color = \"red\"),\n                     color = I('#caced8'),\n                     marker = list(line = list(width = 2, color = '#caced8'))\n                    ) %&gt;%\n  layout(title = \"Distribution of Rainfall from 2014 to 2023\",\n         yaxis = list(title = \"Rainfall volume (mm)\"),\n         xaxis = list(title = \"Year\"))\n\n# Show the plot\np8_plotly\n\n\n\n\n\nKruskal-Wallis test result at the top indicates a significant difference in rainfall distribution across the years (p-value &lt; 0.01), suggesting that at least one year has a statistically different total rainfall volume compared to the others.\nfrom the lines connecting the years we can observe that some years trend towards significance when the pHolm-adj is less than 1.00. Hence we can reject the null hypothesis and say that the rainfall over the years is statistically significant.\n\n\nHypothesis:\nH0: There is no statistical difference between median daily rainfall from 2014-2023.\nH1: There is statistical difference between median daily rainfall from 2014-2023.\n\np9 &lt;- ggbetweenstats(\n  data = weather_data_imputed,\n  x = Year, \n  y = Daily_Rainfall_Total_mm,\n  type = \"np\",\n  pairwise.display = \"non-significant\",\n  messages = FALSE,\n  title=\"Distribution of Rainfall from 2014 to 2023\",\n  ylab = \"Rainfall volume (mm)\",\n  xlab = \"Year\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12), plot.title=element_text(size=12))\n\np9\n\n\n\n\nWe can dig further into the daily rainfall total to see if there is statistical significant. After undergo the test above, we can observe the test result that overall Kruskal-Wallis test is highly significant (p=2.84e−89), indicating there are differences in the distributions of daily rainfall volumes across the years.\nWe can also observe that some years the median daily rainfall is 0.00 or 0.20 (2014, 2015, 2019, etc.) suggesting low rainfall volume.\n\n\n\n\n\n\n5.2.2 Can We Clearly Identify the ‘Dry’ and ‘Wet’ Month?\nSingapore which is a tropical country, means have no clear identification of the four seasons, but there are certain months which the ‘cooler’ compare to some months. In this section we will be testing the hypothesis on ‘can we clearly identify the ’Dry’ and ‘Wet’ Month’?\nFirst we need to filter the data to get monthly records, code chunk below:\n\nrf_data_month &lt;- weather_data_imputed %&gt;%\n  group_by(Year,Month) %&gt;%\n  summarise(monthly_rainfall = sum(Daily_Rainfall_Total_mm))\n\nrf_data_month$Year &lt;- factor(rf_data_month$Year)\nrf_data_month$Month &lt;- factor(rf_data_month$Month, levels = as.character(1:12))\n\nDT::datatable(rf_data_month,class = \"compact\")\n\n\n\n\n\n\n\nglimpse(rf_data_month)\n\nRows: 120\nColumns: 3\nGroups: Year [10]\n$ Year             &lt;fct&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014,…\n$ Month            &lt;fct&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5,…\n$ monthly_rainfall &lt;dbl&gt; 450.6, 124.0, 728.1, 1296.2, 1621.8, 1026.9, 1070.8, …\n\n\n\ntemp_month &lt;- weather_data_imputed %&gt;%\n  group_by(Year,Month) %&gt;%\n  summarise(median_mean_temp = median(Mean_Temperature),\n            median_max_temp = median(Max_Temperature),\n            median_min_temp = median(Min_Temperature))\n\nDT::datatable(temp_month,class = \"compact\")\n\n\n\n\n\n\nTo see the distribution of the monthly rainfall and Temperature, code chunk below:\n\nDistribution of Monthly RainfallDistribution of Monthly Mean TemperatureDistribution of Monthly Max TemperatureDistribution of Monthly Min Temperature\n\n\n\ncolor_palette &lt;- brewer.pal(\"Set3\", n = length(unique(rf_data_month$Year)))\n\np18 &lt;- ggplot(rf_data_month, aes(x = Month, y = monthly_rainfall, fill = Year)) +\n  geom_bar(stat = \"identity\") +\n  facet_wrap(~Year, scales = \"free_x\") +\n  labs(title = \"Monthly Rainfall From Year 2014 to 2023\",\n       y = \"Rainfall volume (mm)\",\n       x = \"Month\") +\n  theme_minimal() +\n  scale_fill_manual(values = color_palette) +\n  theme(panel.spacing.y = unit(0.5, \"lines\")) # Adjusted for less spacing\n\np18\n\n\n\n\nFrom the distribution of monthly rainfall from year 2014 to 2023, we can observe that the data is not normally distributed, hence non-parametric test will be used later.\n\n\n\np19 &lt;- ggplot(temp_month,\n       aes(y = median_mean_temp,\n           x = Month,\n           colour = Year)) +\n  geom_line(size = 1.5)+\n  facet_wrap(~Year, scales = \"free_x\") +\n  labs(title=\"Monthly mean Temperature From 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Month\")+\n  coord_cartesian(ylim = c(20,35))+\n  scale_x_discrete(limits = 1:12) + # Assuming Month is numeric already\n  theme_minimal() +\n  theme(panel.spacing.y = unit(0.5,\"lines\"))\n\np19\n\n\n\n\nFrom the distribution of monthly mean temperature from year 2014 to 2023, we can observe that the data is not normally distributed, hence non-parametric test will be used later.\n\n\n\np20 &lt;- ggplot(temp_month,\n       aes(y = median_max_temp,\n           x = Month,\n           colour = Year)) +\n  geom_line(size = 1.5)+\n  facet_wrap(~Year, scales = \"free_x\") +\n  labs(title=\"Monthly Maximum Temperature From 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Month\")+\n  coord_cartesian(ylim = c(20,35))+\n  scale_x_discrete(limits = 1:12) + # Assuming Month is numeric already\n  theme_minimal() +\n  theme(panel.spacing.y = unit(0.5,\"lines\"))\n\np20\n\n\n\n\nFrom the distribution of monthly maximum temperature from year 2014 to 2023, we can observe that the data is not normally distributed, hence non-parametric test will be used later.\n\n\n\np21 &lt;- ggplot(temp_month,\n       aes(y = median_min_temp,\n           x = Month,\n           colour = Year)) +\n  geom_line(size = 1.5)+\n  facet_wrap(~Year, scales = \"free_x\") +\n  labs(title=\"Monthly Minimum Temperature From 2014 to 2023\",\n       y = \"Temperature (°C)\",\n       x = \"Month\")+\n  coord_cartesian(ylim = c(20,35))+\n  scale_x_discrete(limits = 1:12) + # Assuming Month is numeric already\n  theme_minimal() +\n  theme(panel.spacing.y = unit(0.5,\"lines\"))\n\np21\n\n\n\n\nFrom the distribution of monthly minimum temperature from year 2014 to 2023, we can observe that the data is not normally distributed, hence non-parametric test will be used later.\n\n\n\n\n5.2.2.1 Hypothesis testing\nTo test Monthly Rainfall From Year 2014 to 2023:\nThe hypothesis is as follows:\nH0: There is no statistical difference between minimum temperature across months.\nH1: There is statistical difference between minimum temperature across months.\n\nMonthly Rainfall over yearsMonthly Mean TemperatureMonthly Maximum TemperatureMonthly Minimum Temperature\n\n\nHypothesis:\nH0: There is no statistical difference in rainfall volume across months.\nH1: There is statistical difference in rainfall volume across months.\n\np22 &lt;- ggbetweenstats(\n  data = rf_data_month,\n  x = Month, \n  y = monthly_rainfall,\n  type = \"np\",\n  messages = FALSE,\n  title=\"Distribution of Rainfall across months 2014 to 2023\",\n  ylab = \"Rainfall volume (mm)\",\n  xlab = \"Month\",\n  ggsignif.args = list(textsize = 4)\n) +\n  theme(text = element_text(size = 12), plot.title=element_text(size=12))\np22\n\n\n\n\nAt CI of 95%, the Kruskal-Wallis test results give a p-value &lt; 0.05, which indicates there is statistical difference in the rainfall volume across different month in Singapore.\n\nFeb has significant different in rainfall volume comparing with Nov and Dec.\n2, 3, 7, 8, 9, 10 can consider ‘Dry’ as median rainfall volume lower or equal to around 1000mm per month.\n4, 5, 6, 11, 12 can consider a ‘Wet’ as median rainfall volume mainly higher than 1400mm per month.\n\n\n\nHypothesis:\nH0: There is no statistical difference between mean temperature across months.\nH1: There is statistical difference between mean temperature across months.\n\np23 &lt;- ggbetweenstats(data = temp_month,\n                      x = Month,\n                      y = median_mean_temp,\n                      type = \"np\",\n                      messages = FALSE,\n                      title = \"Distribution of Mean Temperature by month from 2014 to 2023\",\n                      ylab = \"Temperature (C)\",\n                      xlab = \"Month\",\n                      ggsignif.args = list(textsize =4)) +\n  theme(text = element_text(size = 11),plot.title = element_text(size = 11))\np23\n\n\n\n\nAt CI of 95%, the Kruskal-Wallis test results give a p-value &lt; 0.05, which indicates there is statistical difference in the mean temperature across different month in Singapore.\n\nIt is observed that towards the middle of the 12 months, 5, 6, 7 ,8 ,9 has the highest median mean temperature .\nWhile months 1, 2, 11, 12 has the lowest median mean temperature.\n\n\n\nHypothesis:\nH0: There is no statistical difference between maximum temperature across months.\nH1: There is statistical difference between maximum temperature across months.\n\np24 &lt;- ggbetweenstats(data = temp_month,\n                      x = Month,\n                      y = median_max_temp,\n                      type = \"np\",\n                      messages = FALSE,\n                      title = \"Distribution of Maximum Temperature by month from 2014 to 2023\",\n                      ylab = \"Temperature (C)\",\n                      xlab = \"Month\",\n                      ggsignif.args = list(textsize =4)) +\n  theme(text = element_text(size = 11),plot.title = element_text(size = 11))\np24\n\n\n\n\nAt CI of 95%, the Kruskal-Wallis test results give a p-value &lt; 0.05, which indicates there is statistical difference in the maximum temperature across different month in Singapore.\n\nThe month with highest daily temperature is month 3, 4, 5 which average maximum temperature more than 32 Degree Celsius.\nMonth with lowest daily temperature is January, with only average maximum temperature of 30.85 Degree Celsius.\n\n\n\nHypothesis:\nH0: There is no statistical difference between minimum temperature across months.\nH1: There is statistical difference between minimum temperature across months.\n\np25 &lt;- ggbetweenstats(data = temp_month,\n                      x = Month,\n                      y = median_min_temp,\n                      type = \"np\",\n                      messages = FALSE,\n                      title = \"Distribution of Minimum Temperature by month from 2014 to 2023\",\n                      ylab = \"Temperature (C)\",\n                      xlab = \"Month\",\n                      ggsignif.args = list(textsize =4)) +\n  theme(text = element_text(size = 11),plot.title = element_text(size = 11))\np25\n\n\n\n\nAt CI of 95%, the Kruskal-Wallis test results give a p-value &lt; 0.05, which indicates there is statistical difference in the minimum temperature across different month in Singapore.\n\n\n\nFrom the hypothesis testing, several result can be shown:\n\nDry Month: 2, 3, 7, 8, 9\nWet Month :1, 6, 11, 12\nHot Month: 3, 4, 5, 9, 10\nCool Month: 1, 2, 11, 12\nDry & Hot : 3, 9\nWet & Cool : 1, 11, 12\n\nBy identifying this can help Singapore Government to develop strategies to deal with different situations, and also to see the trend in future if there is shift in different type of month"
  },
  {
    "objectID": "prototyping/Project.html#feasts",
    "href": "prototyping/Project.html#feasts",
    "title": "EDA",
    "section": "feasts",
    "text": "feasts\nfeasts package that is within the tidyvert collection is mainly used for the feature extraction and statistics for time series analysis. Also, feasts package provides a set of tools within the package that it is useful for the analysis of time series data.\nWorking with tidy temporal data that was previously set up using tsibble package, it is able to compute time series features, decomposition, statistical summaries and graphical visualizations. Features extraction is useful in the understanding of the behavior of time series data together with the closely integration of the tidy forecasting workflow used in the fable package.\n\nTime series pattern (time plot)\nTo begin our analysis, we will first start with plotting a time plot using the auto_plot() function to look at the time plot of our dataset. auto_plot() automatically create an appropriate plot of choosen variable against time. In this case, it recognizes humidity level as a time series and produces a time plot as shown below.\nFrom the figure below, we are able to observe that the humidity level fluctuate of high volatility that cause the understanding of the time plot to be rather challenging. In the next few section of the the article we will be looking into the different analysis of the time plot to try to identify if we are able to observed any trend/seasonal/cyclic pattern.\n\n# Filter for specific stations\nweather_filtered &lt;- weather %&gt;% \n  filter(Station %in% c(\"Admiralty\", \"Ang Mo Kio\", \"Changi\"))\n\n# Create a date column from Year and Month\nweather_filtered$Date &lt;- make_date(weather_filtered$Year, weather_filtered$Month)\n\n# Summarize the total rainfall by month for each station\nmonthly_rainfall &lt;- weather_filtered %&gt;%\n  group_by(Station, Day) %&gt;%\n  summarise(Total_Rainfall = sum(Daily.Rainfall.Total..mm., na.rm = TRUE))\n\n# Plot the data\nggplot(monthly_rainfall, aes(x = Day, y = Total_Rainfall, color = Station)) +\n  geom_line() +\n  labs(title = \"Monthly Rainfall by Station\", x = \"Date\", y = \"Total Rainfall (mm)\") +\n  theme_minimal()\n\n\n\n\n\n\nSeasonal plot and seasonal subseries plot\nWith the feasts package, user is able to plot time plot based on the given time period in the dataset. We are also able to use the gg_season() and gg_subseries() to plot the season plot and there change in the seasonality respectively. Without the use of group_by() function, we are able to review the time plot of individual airport using gg_season() and gg_subseries() function. The code below would shown how we are able to use gg_season() to plot the different season plot based on individual airport. Similar technique is used for gg_subseries as well.\nweather_tsibble &lt;- weather_filtered %&gt;%\nmutate(Year = year(Date), Month = month(Date)) %&gt;%\ngroup_by(Station, Year, Month) %&gt;%\nsummarise(Total_Rainfall = sum(Daily.Rainfall.Total..mm., na.rm = TRUE)) %&gt;%\nungroup() %&gt;%\nmutate(Date = make_date(Year, Month)) %&gt;%\nselect(-Year, -Month) %&gt;%\nas_tsibble(index = Date, key = Station)\n# Seasonal decomposition using the feasts package\nweather_decomposed &lt;- weather_tsibble %&gt;%\nmodel(STL(Total_Rainfall ~ season(window = “periodic”)))\n\nweather_tsibble &lt;- weather_filtered %&gt;%\n  mutate(Year = year(Date), Month = month(Date)) %&gt;%\n  group_by(Station, Year, Month) %&gt;%\n  summarise(Total_Rainfall = sum(Daily.Rainfall.Total..mm., na.rm = TRUE)) %&gt;%\n  ungroup() %&gt;%\n  mutate(Date = make_date(Year, Month)) %&gt;%\n  select(-Year, -Month) %&gt;%\n  as_tsibble(index = Date, key = Station)\n\n# Seasonal decomposition using the feasts package\nweather_decomposed &lt;- weather_tsibble %&gt;%\n  model(STL(Total_Rainfall ~ season(window = \"periodic\")))\n\n\nweather_tsibble &lt;- weather_tsibble %&gt;%\n  mutate(Week = factor(isoweek(Date))) %&gt;%\n  as_tsibble(index = Date, key = Station) %&gt;%\n  fill_gaps() %&gt;% # This will fill in the implicit gaps with NA by default\n  mutate(Total_Rainfall = replace_na(Total_Rainfall, 0)) # Replace NA with 0 or use another method to handle NAs\n\n# Now, create the seasonal plots\nseasonal_plots &lt;- weather_tsibble %&gt;%\n  gg_season(Total_Rainfall, period = \"week\") +\n  labs(title = \"Seasonal Plot by Week\",\n       subtitle = \"Individual time plot for each Station\",\n       y = \"Measurement Variable\") +\n  facet_wrap(~ Station, scales = \"free_y\", ncol = 1) +\n  aes(color = Week) +\n  scale_color_manual(values = rainbow(length(unique(weather_tsibble$Week))))\n\n# Print the seasonal plots\nprint(seasonal_plots)\n\n\n\n\n\nseasonal_plots &lt;- weather_tsibble %&gt;%\n  gg_season(Total_Rainfall, period = \"week\") +\n  labs(title = \"Seasonal Plot by Week\",\n       subtitle = \"Individual time plot for each Station\",\n       y = \"Measurement Variable\") +\n  facet_wrap(~ Station, scales = \"free_y\", ncol = 1) +\n  aes(color = Week) +\n  scale_color_manual(values = rainbow(length(unique(weather_tsibble$Week))))\n\nprint(seasonal_plots)"
  },
  {
    "objectID": "prototyping/Project.html#prototype-of-random-forest-model",
    "href": "prototyping/Project.html#prototype-of-random-forest-model",
    "title": "EDA",
    "section": "3.2 Prototype of Random Forest model",
    "text": "3.2 Prototype of Random Forest model\nThe prototype uses randomForest() of the randomForest package to model the property price index using explanatory variable for forecasting, to make predictions on the subsequent periods based on new / unseen data.\n\n# Load the necessary libraries if not already loaded\nlibrary(dplyr)\n\n# Define the cutoff year\ncut_off_year &lt;- 2018\n\n# Define the explanatory variables (you will need to replace this with your actual variables)\nexplanatory_vars &lt;- c(\"Month\", \"Day\", \"Mean_Temperature\", \"Max_Temperature\", \"Min_Temperature\")\n\n# Define the dependent variable (replace 'PropertyPriceIndex' with your actual dependent variable)\ndependent_var &lt;- \"Daily_Rainfall_Total_mm\"\n\n# Convert Date to a numeric year format for filtering\nweather_data_imputed$Year &lt;- as.numeric(format(as.Date(weather_data_imputed$Date), \"%Y\"))\n\n# Split the dataset into training and testing sets\nweather_rf_train &lt;- subset(weather_data_imputed, Year &lt; cut_off_year) %&gt;%\n  select(all_of(explanatory_vars), all_of(dependent_var)) %&gt;%\n  na.omit()\n\nweather_rf_test &lt;- subset(weather_data_imputed, Year &gt;= cut_off_year) %&gt;%\n  select(all_of(explanatory_vars), all_of(dependent_var)) %&gt;%\n  na.omit()\n\n# View the structure of the training and testing sets\nstr(weather_rf_train)\n\n'data.frame':   9921 obs. of  6 variables:\n $ Month                  : int  1 1 1 1 1 1 1 1 1 1 ...\n $ Day                    : int  1 2 3 4 5 6 7 8 9 10 ...\n $ Mean_Temperature       : num  26.7 27.4 27.1 27.1 24.8 25.3 26.7 27.1 25.9 26.8 ...\n $ Max_Temperature        : num  29 30.9 30.4 31.1 26.4 27.1 30.7 31.8 29.3 30.6 ...\n $ Min_Temperature        : num  24.9 25 24.9 24.9 23.3 23.9 24.3 24.7 24.3 24.2 ...\n $ Daily_Rainfall_Total_mm: num  0 0 0 0 18.4 31.2 0 0 2 0 ...\n\nstr(weather_rf_test)\n\n'data.frame':   15337 obs. of  6 variables:\n $ Month                  : int  1 1 1 1 1 1 1 1 1 1 ...\n $ Day                    : int  1 2 3 4 5 6 7 8 9 10 ...\n $ Mean_Temperature       : num  24.8 25.5 26.6 26.1 26 26.8 26.8 26.4 27.2 24.5 ...\n $ Max_Temperature        : num  26.7 27.3 31.1 28.2 29 29.7 30.5 30.3 31.4 26.7 ...\n $ Min_Temperature        : num  23.6 24.3 24.1 25 24.8 24.4 24.2 23.4 25.2 22.8 ...\n $ Daily_Rainfall_Total_mm: num  32.2 0.8 2 0.2 1 0 0 45.8 1.8 29.8 ...\n\n\nThe code chunk below shows the preparation of the dataset based on user selected inputs, including the partitioning of the dataset into training and testing datasets based on the user selected year to start forecasting from.\n\n# Define user-selected model parameters\nntree &lt;- 500    # Replace with user-selected value for number of trees\nmtry &lt;- 3       # Replace with user-selected value for number of variables tried at each split\nnodesize &lt;- 5   # Replace with user-selected value for minimum size of terminal nodes\n\n# Train the Random Forest model using the training data\n# 'dependent_var' should be replaced with the actual name of your dependent variable column\nrf_model &lt;- randomForest(Daily_Rainfall_Total_mm ~ ., data = weather_rf_train, ntree = ntree, mtry = mtry, nodesize = nodesize, importance = TRUE, na.action = na.omit)\n\n# View the model summary\nprint(rf_model)\n\n\nCall:\n randomForest(formula = Daily_Rainfall_Total_mm ~ ., data = weather_rf_train,      ntree = ntree, mtry = mtry, nodesize = nodesize, importance = TRUE,      na.action = na.omit) \n               Type of random forest: regression\n                     Number of trees: 500\nNo. of variables tried at each split: 3\n\n          Mean of squared residuals: 77.07371\n                    % Var explained: 44.61\n\n# View variable importance\nimportance(rf_model)\n\n                   %IncMSE IncNodePurity\nMonth             74.35007      165188.8\nDay               39.86414      183153.1\nMean_Temperature  47.16387      216357.8\nMax_Temperature   55.35003      212034.3\nMin_Temperature  156.16294      489505.7\n\n\nThe code chunk below uses randomForest() to create the model using the training dataset with the user selected model parameters.\n\n# Predictions and performance metrics\npredictions_train &lt;- predict(rf_model, newdata = weather_rf_train)\nrmse_train &lt;- sqrt(mean((weather_rf_train$Daily_Rainfall_Total_mm - predictions_train)^2))\nmae_train &lt;- mean(abs(weather_rf_train$Daily_Rainfall_Total_mm - predictions_train))\n\npredictions_test &lt;- predict(rf_model, newdata = weather_rf_test)\nrmse_test &lt;- sqrt(mean((weather_rf_test$Daily_Rainfall_Total_mm - predictions_test)^2))\nmae_test &lt;- mean(abs(weather_rf_test$Daily_Rainfall_Total_mm - predictions_test))\n\n# Combine the performance metrics into a data frame\nperformance_metrics &lt;- data.frame(\n  Error = c('RMSE', 'MAE'),\n  Train = c(rmse_train, mae_train),\n  Test = c(rmse_test, mae_test)\n)\n\n\n# 表 1 实际值与预测值和残差\n# Combine actual and predicted values for train and test sets\nresults &lt;- data.frame(Actual = weather_rf_test$Daily_Rainfall_Total_mm, Predicted = predictions_test, DataPartition = \"Test\")\ntrain_results &lt;- data.frame(Actual = weather_rf_train$Daily_Rainfall_Total_mm, Predicted = predictions_train, DataPartition = \"Train\") %&gt;%\n  bind_rows(results)\n\n# Plot for actual vs predicted values\np_actual_vs_predicted &lt;- ggplot(data = train_results, aes(x = Actual, y = Predicted, color = DataPartition)) +\n  geom_abline(intercept = 0, slope = 1, color = \"red\", linetype = \"dashed\") +\n  geom_point(alpha = 0.5) +\n  labs(x = \"Actual\", y = \"Predicted\", title = \"Actual vs. Predicted Values\") +\n  theme_bw()\n\n# Plot for residuals\ntrain_results$Residuals &lt;- train_results$Actual - train_results$Predicted\np_residuals &lt;- ggplot(data=train_results, aes(x=Predicted, y=Residuals, colour = DataPartition)) +\n  geom_point() +\n  geom_hline(yintercept=0, color = 'red', linetype = 'dashed') +\n  labs(title = \"Residual Plot\") +\n  theme_bw()\n\n# Print the plots (you can also save them using ggsave())\nprint(p_actual_vs_predicted)\n\n\n\nprint(p_residuals)\n\n\n\n\n\n# 表 2 变量重要性\n# Get the importance matrix and convert it to a data frame\nimportance_data &lt;- as.data.frame(importance(rf_model))\nnames(importance_data)  # This should print the correct column names\n\n[1] \"%IncMSE\"       \"IncNodePurity\"\n\n# The correct column names are \"%IncMSE\" and \"IncNodePurity\"\n# Now we will plot using the correct names\np_importance &lt;- ggplot(importance_data, aes(x = row.names(importance_data), y = IncNodePurity)) +\n  geom_bar(stat=\"identity\") +\n  theme_bw() +\n  labs(x = \"Variables\", y = \"Increase in Node Purity\", title = \"Variable Importance\") +\n  coord_flip() # Flips the axes for a horizontal plot\n\nprint(p_importance)\n\n\n\n\n\n# 表3 时间序列预测\n# Create a 'Date' column for weather_rf_train, assuming the year 2021 for simplicity.\nweather_rf_train$Date &lt;- as.Date(paste('2021', as.character(weather_rf_train$Month), as.character(weather_rf_train$Day), sep='-'), format='%Y-%m-%d')\n\n# Assuming the length of predictions_test matches the number of rows in weather_rf_test\nweather_rf_test$Year &lt;- rep(2021, nrow(weather_rf_test))  # Replace with the actual year(s) if necessary\nweather_rf_test$Date &lt;- as.Date(paste(weather_rf_test$Year, weather_rf_test$Month, weather_rf_test$Day, sep=\"-\"), format=\"%Y-%m-%d\")\n\n# Ensure the 'Date' column is not empty\nif(length(weather_rf_test$Date) == 0) {\n  stop(\"The 'Date' column in 'weather_rf_test' is empty.\")\n}\n\n# Assuming predictions_test and weather_rf_test$Date have been verified to be of equal length, create the results data frame.\nresults &lt;- data.frame(Date = weather_rf_test$Date, Predicted = predictions_test, Actual = weather_rf_test$Daily_Rainfall_Total_mm)\n\n# Now plot the time series\np_time_series &lt;- ggplot() +\n  geom_line(data = weather_rf_train, aes(x = Date, y = Daily_Rainfall_Total_mm), color = \"green\", size = 0.7) +\n  geom_line(data = results, aes(x = Date, y = Predicted), color = \"blue\", linetype = \"dotted\", size = 0.7) +\n  labs(y = \"Rainfall (mm)\", x = \"Date\", title = \"Time Series of Rainfall (Actual in green, Predicted in blue)\") +\n  theme_bw()\n\n# Print the time series plot\nprint(p_time_series)"
  }
]