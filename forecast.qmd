---
title: "Untitled"
---

# **1 Overview**

## **1.1 Setting the scene**

This exercise serves as a prototype for one of the modules, i.e. the nowcasting / forecasting models, used in the group's proposed Shiny application for the Visual Analytics Project. Prototyping of the Shiny App has the following benefits:

-   Validate the feasibility and effectiveness of your ideas or analytical approaches

-   Gather feedback from stakeholders or end-users early in the development process

-   Iteratively update the prototype, adding new features, improving usability, and refining visualizations until the desired outcome is achieved

-   Facilitates collaboration among team members or stakeholders

-   Identify and address potential issues early in the development process

## **1.2 The task**

As part of this prototyping exercise, the following objectives are fulfilled:

-   Identified and evaluated the necessary R packages in R CRAN

-   Prepared and tested the R codes for the models

-   Determined the parameters and outputs that will be exposed on the Shiny applications

-   Selected the appropriate Shiny UI components for exposing the parameters

## **1.3 Problem statement of group project**

Forecasting Singapore's private housing index is beset with difficulties, arising from the complex interplay among several factors such as economic indicators, employment trends, policy changes, and current market sentiments. The intricacy is further intensified by the delayed nature of crucial indices and indicators, which are commonly released with a substantial time delay, usually spanning from one to three months. These delays impede the capacity to accurately predict private house price changes, as the most up-to-date data required for precise forecasts is not easily accessible.

To tackle this problem, it is necessary to utlilise nowcasting models that can precisely forecast the future direction of the Singapore private housing market. The objective is to utilize these models to provide stakeholders, including homebuyers, sellers, investors, and policy makers, with timely and convenient access to predictive data via visual analytics.

# **2 Data Preparation**

## **2.1 Loading R packages**

The `pacman::p_load()` function is used to install and load the required R packages into the R environment, as below.

-   [tidyverse](https://www.tidyverse.org/): collection of R packages designed for data science

-   [randomForest](https://cran.r-project.org/web/packages/randomForest/): an R library for classification and regression based on a forest of trees using random inputs

-   [plotly](https://plotly.com/r/): an R graphing library for plotting interactive, publication-quality graphs

-   [gbm](https://cran.r-project.org/web/packages/gbm/): an R library for Freund and Schapire's AdaBoost algorithm and Friedman's gradient boosting machine

-   [prophet](https://cran.r-project.org/web/packages/prophet/): an R library that implements a procedure for forecasting time series data based on an additive model developed by Facebook

-   [knitr](https://cran.r-project.org/web/packages/knitr/): an R package for dynamic report generation

-   [patchwork](https://cran.r-project.org/web/packages/patchwork/): an R package for preparing composite figure created using ggplot2

```{r}
pacman::p_load(tidyverse, randomForest, plotly, gbm, prophet, knitr, patchwork)
```

```{r}
weather_data_imputed<- readRDS("prototyping/data/weather_imputed_11stations.rds")
```

## **3.2 Prototype of Random Forest model**

The prototype uses **randomForest()** of the randomForest package to model the property price index using explanatory variable for forecasting, to make predictions on the subsequent periods based on new / unseen data.

```{r}
# set random seed to get consistent result
set.seed(123)

# choose whether to model actual values or difference across periods ('actual' or 'diff)
data_selected = data_quarter_diff
selected = "diff"
# this is cutoff value of year for testing data selection                    
cut_off_year = 2020
# to do if/case statement in Shiny for switching between different time series
data_selected <- data_selected %>% 
  rename(dependentVariable = PR_All)
data_actual_temp <- data_quarter_actual %>% 
  rename(dependentVariable = PR_All) %>% 
  select(Date, dependentVariable)

# to store explanatory variables - will be user inputs
explanatory <- c("Cement", "SteelBar", "Granite", "ConcretingSand", "ReadyMixConcrete", "Index", "Bill1Yr", "Bond2Yr", "Bond5Yr", "Bond10Yr", "Rate", 'PR_All_Lag_1', 'PR_All_Lag_2', 'PR_All_Lag_3', 'PR_All_Lag_4')
# to store dependent variable to model
dependent <- c("PR_All")
# variable for number of trees - user input (values from 100 - 500)
ntree <- 300
# number of variables sampled for tree (values from 2 - 8)
mtry <- 6
# maximal size of terminal nodes in each tree (values from 1 - 8)
nodesize <- 6
```

The code chunk below shows the preparation of the dataset based on user selected inputs, including the partitioning of the dataset into training and testing datasets based on the user selected year to start forecasting from.

```{r}
# preparing the dataset based on user selected variables
ppi_rf_train <- subset(data_selected, as.numeric(year(Date)) < cut_off_year) %>% 
  select(-Date, -QuarterLabel) %>%
  select(all_of(explanatory), dependentVariable) %>% 
  na.omit()
ppi_rf_test <- subset(data_selected, as.numeric(year(Date)) >= cut_off_year) %>% 
  select(-Date, -QuarterLabel) %>% 
  select(all_of(explanatory), dependentVariable)
```

The code chunk below uses **randomForest()** to create the model using the training dataset with the user selected model parameters.

```{r}
# specifying the model based on user selected variables for the model
rf_model <- randomForest(dependentVariable ~ ., data = ppi_rf_train, ntree = ntree, mtry = mtry, nodesize = nodesize, importance = T, na.action = na.omit)  
```

```{r}
# using trained model to predict both training and test dataset and calculate RMSE
predictions_train <- predict(rf_model, newdata = ppi_rf_train)
rmse_train <- sqrt(mean((ppi_rf_train$dependentVariable - predictions_train)^2))
mae_train <- mean(abs(ppi_rf_train$dependentVariable - predictions_train))

predictions <- predict(rf_model, newdata = ppi_rf_test)
rmse_test <- sqrt(mean((ppi_rf_test$dependentVariable - predictions)^2))
mae_test <- mean(abs(ppi_rf_test$dependentVariable - predictions))

printout <- data.frame(
  Error = c('RMSE', 'MAE'),
  Train = c(rmse_train, mae_train),
  Test = c(rmse_test, mae_test))

# Tab 1 - plot actual vs predicted
results <- data.frame(Actual = ppi_rf_test$dependentVariable, Predicted = predictions, "DataPartition" = "Test")
train_test <- data.frame(Actual = ppi_rf_train$dependentVariable, Predicted = predictions_train, "DataPartition" = "Train") %>% 
  bind_rows(results)
x_lim_min <- floor(train_test['Actual'] %>% min())
y_lim_min <- floor(train_test['Predicted'] %>% min())
x_lim_max <- ceiling(train_test['Actual'] %>% max())
y_lim_max <- ceiling(train_test['Predicted'] %>% max())

p1a <- ggplot(data = train_test, 
             aes(x = Actual, 
                 y = Predicted, 
                 color = DataPartition)) +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +  # Add a diagonal line for reference
  geom_point(alpha = 0.5) +
  labs(x = "Actual", 
       y = "Predicted", 
       title = "Actual vs. Predicted Values") + 
  scale_x_continuous(limits = c(min(x_lim_min, y_lim_min), max(x_lim_max, y_lim_max))) +
  scale_y_continuous(limits = c(min(x_lim_min, y_lim_min), max(x_lim_max, y_lim_max))) +
  theme_bw()

# Tab 1 - to plot residuals
train_test$Residuals <- train_test$Actual - train_test$Predicted
p1b <- ggplot(data=train_test, aes(x=Predicted, y=Residuals, colour = DataPartition)) + 
  geom_point() +
  geom_hline(yintercept=0, color = 'Red', linetype = 'dashed') +
  labs(title = "Residual Plot") +
  theme_bw()

# Tab 3 - to plot time series of index (with forecasting)

if (selected == "diff") {
  results <- recover_actual(results, data_actual_temp$dependentVariable[nrow(data_actual_temp) - nrow(results)])
}
 
results <- results %>% 
  mutate(Date = (data_actual_temp$Date[(nrow(data_actual_temp) - nrow(results) + 1) : (nrow(data_actual_temp))]))
 
p1c <- ggplot() +
  geom_line(data=data_actual_temp,
            aes(x = Date, y = dependentVariable),
            colour = "green",
            size = 0.7) +
  geom_line(data=results,
            aes(x=Date, y = Predicted, color = DataPartition),
            linetype = 'dotted',
            size = 0.7) +
  labs(y = "Price Index",
       x = 'Year',
       title = "Time Series of Quarterly Price Index (Actual index in green)") +
  theme_bw()
```

```{r}
ggplotly(p1a) 
```

```{r}
varImpPlot(rf_model) 
```

```{r}
ggplotly(p1c)
```
